{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3132f025-57b8-4c26-8361-46967e82833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA:0 _CudaDeviceProperties(name='NVIDIA GeForce GTX 1070', major=6, minor=1, total_memory=8105MB, multi_processor_count=15) [(8004.625, 8105.0625)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# logging jupiterlab notebook \n",
    "import logging\n",
    "nblog = open(\"nb.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# GPU infos\n",
    "num_GPUs = torch.cuda.device_count()\n",
    "for i in range(num_GPUs):\n",
    "    info = torch.cuda.get_device_properties(i)\n",
    "    mem_info = torch.cuda.mem_get_info(i)\n",
    "    print(f\"CUDA:{i} {info} [{mem_info[0]/ 1024 ** 2, mem_info[1]/ 1024 ** 2}]\")\n",
    "\n",
    "# variables\n",
    "# operators = ['-', '+', '*', '/']\n",
    "operators = ['+', '-', '*']\n",
    "brackets = ['(', ')']\n",
    "input_chars = [\" \"] + [str(d) for d in range(10)] + [\".\"] + operators + brackets\n",
    "output_chars = [\" \"] + [str(d) for d in range(10)] + [\"-\"]\n",
    "max_number = 999\n",
    "max_digit = 5\n",
    "max_bracket = 3\n",
    "input_dim = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555245d4-25fb-4168-97fa-9685dcf126ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating simple arithematic equations and answers\n",
    "def generate_equation():\n",
    "    # number of numbers will be in the equation\n",
    "    num_digits = random.randint(2, max_digit)  # Choose a random number of digits for each operand\n",
    "\n",
    "    # Generate a list of elements in equation\n",
    "    equations = []\n",
    "    for i in range(num_digits):\n",
    "        equations.append(str(random.randint(0, max_number)))\n",
    "        if i < num_digits - 1:\n",
    "            equations.append(random.choice(operators))\n",
    "\n",
    "    # Add brackets randomly\n",
    "    num_brackets = random.randint(0, max_bracket)\n",
    "    for _ in range(num_brackets):\n",
    "        pos1 = random.randint(0, len(equations) - 1)\n",
    "        while equations[pos1] in operators + brackets:\n",
    "            pos1 += 1\n",
    "        new_equations = equations[:pos1] + ['('] + equations[pos1:]\n",
    "        \n",
    "        pos2 = random.randint(pos1 + 2, len(new_equations))\n",
    "        while 2 < pos2 < len(new_equations) and new_equations[pos2 - 1] in operators + brackets:\n",
    "            pos2 += 1\n",
    "        if pos2 == len(new_equations):\n",
    "            continue\n",
    "        new_equations = new_equations[:pos2] + [')'] + new_equations[pos2:]\n",
    "        equations = new_equations\n",
    "\n",
    "    # concatenate them into a single string\n",
    "    final_equation = \"\".join(equations)\n",
    "    return final_equation\n",
    "\n",
    "# evaluate the equation and get the result\n",
    "def evaluate_equation(equation):\n",
    "    try:\n",
    "        # result = f\"{{:.6f}}\".format(eval(equation)).zfill(input_dim)\n",
    "        result = str(eval(equation))\n",
    "        return result\n",
    "    except ZeroDivisionError:\n",
    "        return \" \" * input_dim\n",
    "\n",
    "# function to generate a string equation with answer\n",
    "def generate_eq():\n",
    "    # Generate and evaluate a random equation\n",
    "    equation = generate_equation()\n",
    "    result = evaluate_equation(equation)\n",
    "    return equation, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d91eb00-3b10-440d-8671-ba2020ae13fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('977-392-(789)-875', '-1079')\n",
      "('821-249', '572')\n",
      "('64-956-682*115+179', '-79143')\n",
      "('986-750*188', '-140014')\n",
      "('819-787', '32')\n"
     ]
    }
   ],
   "source": [
    "# generate some examples\n",
    "for _ in range(5):\n",
    "    print(generate_eq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3025da8-7ac2-4a0b-b121-39304e6c48f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input string length: 25\n",
      "Max result string length: 15\n",
      "Min result string: -646317433909\n",
      "Max result string: 420998436312660\n",
      "Number of invalid input string: 0/100000 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# run the generation function many times to get the maxium length of the equation and maximum range of the answer\n",
    "num_trail = 100000\n",
    "max_len_eq = 0\n",
    "max_len_result = 0\n",
    "max_result = float(-np.inf)\n",
    "min_result = float(np.inf)\n",
    "max_result_str = None\n",
    "min_result_str = None\n",
    "invalid_count = 0\n",
    "for _ in range(num_trail):\n",
    "    equation, result = generate_eq()\n",
    "    if \"!\" not in result:\n",
    "        fresult = float(result)\n",
    "        if fresult > max_result:\n",
    "            max_result = fresult\n",
    "            max_result_str = result\n",
    "        if fresult < min_result:\n",
    "            min_result = fresult\n",
    "            min_result_str = result\n",
    "    else:\n",
    "        invalid_count += 1\n",
    "    len_eq, len_result = len(equation), len(result)\n",
    "    max_len_eq = len_eq if len_eq > max_len_eq else max_len_eq\n",
    "    max_len_result = len_result if len_result > max_len_result else max_len_result\n",
    "\n",
    "print(f\"Max input string length: {max_len_eq}\")\n",
    "print(f\"Max result string length: {max_len_result}\")\n",
    "print(f\"Min result string: {min_result_str}\")\n",
    "print(f\"Max result string: {max_result_str}\")\n",
    "print(f\"Number of invalid input string: {invalid_count}/{num_trail} = {invalid_count/num_trail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e134e9-1d01-4b0d-9b9e-66b1a14f3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.', '+', '-', '*', '(', ')'] input_embed_dim 17\n",
      "output_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'] output_embed_dim 12\n",
      "==========[input_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      ". [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "+ [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "* [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "( [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      ") [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[output_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[input_embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 .\n",
      "12 +\n",
      "13 -\n",
      "14 *\n",
      "15 (\n",
      "16 )\n",
      "==========[output_embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 -\n"
     ]
    }
   ],
   "source": [
    "# the embedding dimensions and mappings\n",
    "input_embed_dim = len(input_chars)\n",
    "output_embed_dim = len(output_chars)\n",
    "print(\"input_chars\", input_chars, \"input_embed_dim\", input_embed_dim)\n",
    "print(\"output_chars\", output_chars, \"output_embed_dim\", output_embed_dim)\n",
    "input_embed_map = {e: np.eye(input_embed_dim)[i] for i, e in enumerate(input_chars)}\n",
    "output_embed_map = {e: np.eye(output_embed_dim)[i] for i, e in enumerate(output_chars)}\n",
    "input_embed_inverse_map = {i: k for i, k in enumerate(input_embed_map.keys())}\n",
    "output_embed_inverse_map = {i: k for i, k in enumerate(output_embed_map.keys())}\n",
    "\n",
    "print(\"==========[input_embed_map]============\")\n",
    "for k in input_embed_map.keys():\n",
    "    print(k, input_embed_map[k])\n",
    "\n",
    "print(\"==========[output_embed_map]============\")\n",
    "for k in output_embed_map.keys():\n",
    "    print(k, output_embed_map[k])\n",
    "\n",
    "print(\"==========[input_embed_inverse_map]============\")\n",
    "for k in input_embed_inverse_map.keys():\n",
    "    print(k, input_embed_inverse_map[k])\n",
    "    \n",
    "print(\"==========[output_embed_inverse_map]============\")\n",
    "for k in output_embed_inverse_map.keys():\n",
    "    print(k, output_embed_inverse_map[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4562a51-d95a-4493-a419-e9514d465d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input data: [('687+598', '1285'), ('907*599', '543293')]\n",
      "raw input size: input=(2, 25, 17), output=(2, 25, 12)\n",
      "time_spent: 0.0006783008575439453s\n"
     ]
    }
   ],
   "source": [
    "# function to generate neural netowrk (nn) data for the Transformer\n",
    "def generate_nn_data(num_sample, outout_raw_data_pair=False):\n",
    "    data_pair = [generate_eq() for _ in range(num_sample)]\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for i in range(num_sample):\n",
    "        i_str = data_pair[i][0]\n",
    "        o_str = data_pair[i][1]\n",
    "        \n",
    "        i_vec = np.zeros((input_dim, input_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(i_str):\n",
    "            i_vec[i] = input_embed_map[char]\n",
    "        input_data.append(i_vec)\n",
    "\n",
    "        j_vec = np.zeros((input_dim, output_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(o_str):\n",
    "            j_vec[i] = output_embed_map[char]\n",
    "        output_data.append(j_vec)\n",
    "\n",
    "    input_data = np.array(input_data, dtype=np.float32)\n",
    "    output_data = np.array(output_data, dtype=np.float32)\n",
    "    if outout_raw_data_pair:\n",
    "        return input_data, output_data, data_pair\n",
    "    else:\n",
    "        return input_data, output_data\n",
    "\n",
    "time_start = time.time()\n",
    "input_data, output_data, data_pair = generate_nn_data(2, outout_raw_data_pair=True)\n",
    "time_spent = time.time() - time_start\n",
    "print(f\"raw input data: {data_pair}\")\n",
    "print(f\"raw input size: input={input_data.shape}, output={output_data.shape}\")\n",
    "print(f\"time_spent: {time_spent}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5819827-45b0-4f19-8d81-3687734080e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : ['687+598                  ', '907*599                  ']\n",
      "output: ['1285                     ', '543293                   ']\n"
     ]
    }
   ],
   "source": [
    "# function to decode the nn data back to string\n",
    "def decode_nn_data(output_nn_data, is_input, apply_float=False):\n",
    "    decoded_output = []\n",
    "    c_batchsize =  output_nn_data.shape[0]\n",
    "    c_slen =  output_nn_data.shape[1]\n",
    "    if is_input:\n",
    "        embed_inverse_map = input_embed_inverse_map\n",
    "    else:\n",
    "        embed_inverse_map = output_embed_inverse_map\n",
    "    for b in range(c_batchsize):\n",
    "        e_output = [embed_inverse_map[np.argmax(output_nn_data[b][s])] for s in range(c_slen)]\n",
    "        joint_e_output = \"\".join(e_output)\n",
    "        if apply_float:\n",
    "            try:\n",
    "                decoded_output.append(float(joint_e_output))\n",
    "            except:\n",
    "                decoded_output.append(0.0)\n",
    "        else:\n",
    "            decoded_output.append(joint_e_output)\n",
    "    return decoded_output\n",
    "print(f\"input : {decode_nn_data(input_data, is_input=True, apply_float=False)}\")\n",
    "print(f\"output: {decode_nn_data(output_data, is_input=False, apply_float=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b81ff04-5ed9-4d14-8ca5-0efe4ca75ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "input: ['776-41-988*497-940       ', '288+(773)+633            '], output: ['-491241                  ', '1694                     ']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n",
      "input: ['920*338                  ', '453*266+824*((937))+95   '], output: ['310960                   ', '892681                   ']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n",
      "input: ['939*227+822              ', '82-896                   '], output: ['213975                   ', '-814                     ']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n"
     ]
    }
   ],
   "source": [
    "# our custom pytorch dataset class\n",
    "class CustomDataset(data_utils.Dataset):\n",
    "    def __init__(self, num_sample, random_seed=0):\n",
    "        random.seed(0)\n",
    "        self.num_sample = num_sample\n",
    "        self.refresh_data()\n",
    "\n",
    "    def refresh_data(self):\n",
    "        print(\"refreshing dataset...\")\n",
    "        self.input_data, self.output_data = generate_nn_data(self.num_sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.output_data[idx]\n",
    "\n",
    "train_dataset = CustomDataset(6)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=2)\n",
    "for i in train_dataloader:\n",
    "    print(f\"input: {decode_nn_data(i[0].numpy(), is_input=True)}, output: {decode_nn_data(i[1].numpy(), is_input=False)}\")\n",
    "    print(f\"input size: {i[0].shape}, output size: {i[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62568ee-b33a-4c72-96cb-98be9069c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes and functions for our basic Transformer model\n",
    "class SwiGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        return F.silu(gate) * x\n",
    "\n",
    "class MyActF(nn.Module):\n",
    "    def __init__(self, mode=\"silu\"):\n",
    "        super().__init__()\n",
    "        if mode == \"leaky_relu\":\n",
    "            self.act_f = nn.LeakyReLU(negative_slope=0.01)\n",
    "        elif mode == \"relu\":\n",
    "            self.act_f = nn.ReLU()\n",
    "        elif mode == \"gelu\":\n",
    "            self.act_f = nn.GELU()\n",
    "        elif mode in [\"silu\", \"swish\"]:\n",
    "            self.act_f = nn.SiLU()\n",
    "        elif mode == \"hardswish\":\n",
    "            self.act_f = nn.Hardswish()\n",
    "        elif mode == \"SwiGLU\":\n",
    "            self.act_f = SwiGLU()\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act_f(x)\n",
    "\n",
    "\n",
    "class BatchRenorm(torch.jit.ScriptModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        eps: float = 1e-3,\n",
    "        momentum: float = 0.01,\n",
    "        affine: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"running_std\", torch.ones(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"num_batches_tracked\", torch.tensor(0, dtype=torch.long))\n",
    "        self.weight = torch.nn.Parameter(torch.ones(num_features, dtype=torch.float))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(num_features, dtype=torch.float))\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        self.step = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        raise NotImplementedError()  # pragma: no cover\n",
    "\n",
    "    @property\n",
    "    def rmax(self) -> torch.Tensor:\n",
    "        return (2 / 35000 * self.num_batches_tracked + 25 / 35).clamp_(1.0, 3.0)\n",
    "\n",
    "    @property\n",
    "    def dmax(self) -> torch.Tensor:\n",
    "        return (5 / 20000 * self.num_batches_tracked - 25 / 20).clamp_(0.0, 5.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self._check_input_dim(x)\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        if self.training:\n",
    "            dims = [i for i in range(x.dim() - 1)]\n",
    "            batch_mean = x.mean(dims)\n",
    "            batch_std = x.std(dims, unbiased=False) + self.eps\n",
    "            r = (batch_std.detach() / self.running_std.view_as(batch_std)).clamp_(1 / self.rmax, self.rmax)\n",
    "            d = ((batch_mean.detach() - self.running_mean.view_as(batch_mean)) / self.running_std.view_as(batch_std)).clamp_(-self.dmax, self.dmax)\n",
    "            x = (x - batch_mean) / batch_std * r + d\n",
    "            self.running_mean += self.momentum * (batch_mean.detach() - self.running_mean)\n",
    "            self.running_std += self.momentum * (batch_std.detach() - self.running_std)\n",
    "            self.num_batches_tracked += 1\n",
    "        else:\n",
    "            x = (x - self.running_mean) / self.running_std\n",
    "        if self.affine:\n",
    "            x = self.weight * x + self.bias\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BatchRenorm1d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() not in [2, 3]:\n",
    "            raise ValueError(\"expected 2D or 3D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm2d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(\"expected 4D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm3d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 5:\n",
    "            raise ValueError(\"expected 5D input (got {x.dim()}D input)\")\n",
    "\n",
    "class MyNorm(nn.Module):\n",
    "    def __init__(self, input_dim, mode=\"BatchNorm\"):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        if mode == \"LayerNorm\":\n",
    "            self.norm = nn.LayerNorm(input_dim)\n",
    "        elif mode == \"BatchNorm\":\n",
    "            self.norm = nn.BatchNorm1d(input_dim)\n",
    "        elif mode == \"BatchRenorm\":\n",
    "            self.norm = BatchRenorm1d(input_dim)\n",
    "        elif mode == \"GroupNorm\":\n",
    "            self.num_groups = 8\n",
    "            self.remainder_dim = None\n",
    "            self.rounded_input_dim = None\n",
    "            if self.num_groups > input_dim:\n",
    "                self.num_groups = 1\n",
    "                self.remainder_dim = 0\n",
    "                self.rounded_input_dim = input_dim\n",
    "            else:\n",
    "                self.remainder_dim = input_dim % self.num_groups\n",
    "                self.rounded_input_dim = input_dim - self.remainder_dim\n",
    "            self.norm = nn.GroupNorm(self.num_groups, self.rounded_input_dim)\n",
    "            if self.remainder_dim > 0:\n",
    "                self.remainder_norm = nn.LayerNorm(self.remainder_dim)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == \"GroupNorm\":\n",
    "            if self.remainder_dim == 0:\n",
    "                self.norm(x)\n",
    "            else:\n",
    "                split_x1, split_x2 = torch.split(x, [self.rounded_input_dim, self.remainder_dim])\n",
    "                norm_x1 = self.norm(split_x1)\n",
    "                norm_x2 = self.remainder_norm(split_x2)\n",
    "                return torch.cat([norm_x1, norm_x2], -1)\n",
    "        else:\n",
    "            return self.norm(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, token_dim: int, dropout: float = 0.0, max_len: int = 5000, learnable: bool = False):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.learnable = learnable\n",
    "        if self.learnable:\n",
    "            self.pe = nn.Parameter(torch.normal(mean=0, std=0.001, size=(1, max_len, token_dim)))\n",
    "        else:\n",
    "            position = torch.arange(max_len).unsqueeze(1)\n",
    "            div_term = torch.exp(torch.arange(0, token_dim, 2) * (-math.log(10000.0) / token_dim))\n",
    "            pe = torch.zeros(1, max_len, token_dim)\n",
    "            pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "            pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "            self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MyTransformerEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_token_dim=64,\n",
    "                 output_token_dim=16,\n",
    "                 num_token=20,\n",
    "                 nhead=16,\n",
    "                 dim_feedforward=256,\n",
    "                 dropout=0.1,\n",
    "                 activation='gelu',\n",
    "                 nlayers=3,\n",
    "                 positional_encoding=True,\n",
    "                 proj_norm_mode=\"LayerNorm\",\n",
    "                 ):\n",
    "        super(MyTransformerEncoder, self).__init__()\n",
    "        self.input_token_dim = input_token_dim\n",
    "        self.output_token_dim = output_token_dim\n",
    "        self.num_token = num_token\n",
    "        self.positional_encoding = positional_encoding\n",
    "        if input_token_dim % 2 == 0:\n",
    "            self.corrected_input_token_dim = input_token_dim\n",
    "        else:\n",
    "            self.corrected_input_token_dim = input_token_dim + 1\n",
    "        self.transformer_pre_projection = nn.Sequential(\n",
    "            nn.Linear(self.input_token_dim, self.corrected_input_token_dim, bias=False),\n",
    "            MyNorm(self.corrected_input_token_dim, mode=proj_norm_mode),\n",
    "            MyActF(activation),\n",
    "        )\n",
    "        if positional_encoding:\n",
    "            self.pos_encoder = PositionalEncoding(token_dim=self.corrected_input_token_dim, dropout=0.0, max_len=num_token, learnable=False)\n",
    "        else:\n",
    "            self.pos_encoder = None\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.corrected_input_token_dim,\n",
    "                                                   nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation=activation,\n",
    "                                                   batch_first=True,\n",
    "                                                   norm_first=True,)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.transformer_final_projection = nn.Sequential(\n",
    "            nn.Linear(self.corrected_input_token_dim, self.output_token_dim, bias=True),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, num_token, input_token_dim]\n",
    "        output:\n",
    "            y: Tensor, shape [batch_size, num_token, output_token_dim]\n",
    "        \"\"\"\n",
    "        bs, t, d = x.size(0), x.size(1), x.size(2)\n",
    "        assert d == self.input_token_dim\n",
    "        \n",
    "        x_t = x.view(bs * t, d).contiguous()\n",
    "        proj_x = self.transformer_pre_projection(x_t)  # [batch_size, num_token, input_token_dim]\n",
    "        proj_x_t = proj_x.view(bs, t, self.corrected_input_token_dim).contiguous()\n",
    "        \n",
    "        # proj_x_t = x\n",
    "        \n",
    "        if self.positional_encoding:\n",
    "            endcoded_x = self.pos_encoder(proj_x_t)\n",
    "        else:\n",
    "            endcoded_x = proj_x_t\n",
    "        transformed_x = self.transformer_encoder(endcoded_x)\n",
    "        transformed_x_t = transformed_x.view(bs * t, self.corrected_input_token_dim).contiguous()\n",
    "        proj_transformed_x = self.transformer_final_projection(transformed_x_t).view(bs, t, self.output_token_dim).contiguous()\n",
    "        return proj_transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6a3802-81a7-4fff-8d4e-4557be38346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "\n",
    "# a simple average meter class for monitoring averages\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count if self.count != 0 else 0\n",
    "        \n",
    "# function to get memory usage\n",
    "def mem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 ** 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e51d4d-da49-46ee-95ad-7daa07075ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "refreshing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxchu/miniconda3/envs/tfcal_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# training variables\n",
    "num_epoch = 1000\n",
    "batch_size = 400\n",
    "test_batch_size = batch_size * 4\n",
    "num_of_sample_per_epoch = batch_size * 1000\n",
    "num_of_test_sample = 10000\n",
    "lr = 1e-5\n",
    "lr_factor = 0.1\n",
    "lr_patience = 3\n",
    "lr_threshold=lr * 0.1\n",
    "warmup_epoch = 5\n",
    "warmup_factor = 5\n",
    "wd = 0.0001\n",
    "GPUs = list(range(num_GPUs))\n",
    "\n",
    "# datasets\n",
    "train_dataset = CustomDataset(num_of_sample_per_epoch)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataset = CustomDataset(num_of_test_sample, random_seed=1234567890)\n",
    "test_dataloader = data_utils.DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "# model\n",
    "model = MyTransformerEncoder(\n",
    "    input_token_dim=input_embed_dim,\n",
    "    output_token_dim=output_embed_dim,\n",
    "    num_token=input_dim,\n",
    "    nhead=6,\n",
    "    dim_feedforward=1024,\n",
    "    dropout=0.1,\n",
    "    activation='gelu',\n",
    "    nlayers=64,\n",
    "    positional_encoding=True,\n",
    "    proj_norm_mode=\"LayerNorm\", # LayerNorm BatchNorm\n",
    ")\n",
    "model = torch.nn.DataParallel(model, device_ids=GPUs).cuda()\n",
    "\n",
    "# optimizer\n",
    "train_parameters = model.parameters()\n",
    "optimizer = torch.optim.AdamW(train_parameters, lr=lr, weight_decay=wd)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=lr_factor,\n",
    "    patience=lr_patience,\n",
    "    threshold=lr_threshold,\n",
    "    threshold_mode='rel')\n",
    "\n",
    "# loss\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"mean\").cuda()\n",
    "# loss_function = nn.MSELoss(reduction=\"mean\")\n",
    "# class CustomLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomLoss, self).__init__()\n",
    "#         self.mseloss = nn.MSELoss(reduction='mean')\n",
    "\n",
    "#     def forward(self, output, target):\n",
    "#         batch_size = output.size(0)\n",
    "#         n_token = output.size(1)\n",
    "#         heatmaps_pred = output.reshape((batch_size, n_token, -1)).split(1, 1)\n",
    "#         heatmaps_gt = target.reshape((batch_size, n_token, -1)).split(1, 1)\n",
    "#         loss = 0\n",
    "\n",
    "#         for idx in range(n_token):\n",
    "#             heatmap_pred = heatmaps_pred[idx].squeeze()\n",
    "#             heatmap_gt = heatmaps_gt[idx].squeeze()\n",
    "#             loss += 0.5 * self.mseloss(heatmap_pred, heatmap_gt)\n",
    "\n",
    "#         return loss / n_token\n",
    "# loss_function = CustomLoss().cuda()\n",
    "\n",
    "# helper functions\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def set_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5e43a-8714-46bb-9a4b-81d74e30e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0|lr:1e-05|Memory: 2.75 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4914be392347f5ae8a83b0fdda0515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39487c07910e48ab99095fd0c6b64f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['196+709                  ', '(652*836)-691            ']\n",
      "sample_raw_output ['905                      ', '544381                   '] sample_raw_pred ['1110000000001160001100000', '-12000000000110000-100000']\n",
      "sample_output [905.0, 544381.0] sample_pred [1.11000000000116e+24, 0.0]\n",
      "sample_input ['2-118                    ', '512*105+(659*423)*274    ']\n",
      "sample_raw_output ['-116                     ', '76433178                 '] sample_raw_pred ['-12000000000-10000-100000', '1100000000000100001100000']\n",
      "sample_output [-116.0, 76433178.0] sample_pred [0.0, 1.1000000000001e+24]\n",
      "sample_input ['649+343                  ', '951*167-538              ']\n",
      "sample_raw_output ['992                      ', '158279                   '] sample_raw_pred ['1110000000001160001100000', '112000100000110000-100000']\n",
      "sample_output [992.0, 158279.0] sample_pred [1.11000000000116e+24, 0.0]\n",
      "sample_input ['312+(950-609)+78         ', '17*43+660+517            ']\n",
      "sample_raw_output ['731                      ', '1908                     '] sample_raw_pred ['111000100000111100-100000', '1100000000001100001100000']\n",
      "sample_output [731.0, 1908.0] sample_pred [0.0, 1.1000000000011e+24]\n",
      "sample_input ['92+365                   ', '737-((246))+604          ']\n",
      "sample_raw_output ['457                      ', '1095                     '] sample_raw_pred ['1120000000001160001100000', '-11000100001111001--00000']\n",
      "sample_output [457.0, 1095.0] sample_pred [1.12000000000116e+24, 0.0]\n",
      "sample_input ['44*(624)*605-652         ', '145+204                  ']\n",
      "sample_raw_output ['16610228                 ', '349                      '] sample_raw_pred ['110000000000111000-100000', '1120000000001160001100000']\n",
      "sample_output [16610228.0, 349.0] sample_pred [0.0, 1.12000000000116e+24]\n",
      "sample_input ['850*150*3                ', '450+31                   ']\n",
      "sample_raw_output ['382500                   ', '481                      '] sample_raw_pred ['1110000000001100001100000', '1110000000001160001100000']\n",
      "sample_output [382500.0, 481.0] sample_pred [1.1100000000011e+24, 1.11000000000116e+24]\n",
      "[Epoch:0]|avg_loss:0.470757|lr:1e-05|avg_diff_ratio:155630434926205075456.000|avg_loss_test:0.468086|avg_diff_ratio_test:167030083522056421376.000|best_test_monitor:0.468|best_epoch:1|patient_count:0/3|Memory: 2.80 GB\n",
      "warming up! increase learning rate from 0.00001000 to 0.00005000\n",
      "refreshing dataset...\n",
      "Epoch 1|lr:5e-05|Memory: 3.01 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e0d9aca1c345d880a1a999ce51d02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# monitoring variables\n",
    "begin_epoch = 0\n",
    "avg_loss = AverageMeter()\n",
    "avg_loss_test = AverageMeter()\n",
    "avg_diff_ratio = AverageMeter()\n",
    "avg_diff_ratio_test = AverageMeter()\n",
    "best_test_monitor = float(np.inf)\n",
    "best_epoch = 0\n",
    "patient_count = 0\n",
    "\n",
    "# checkpoint paths\n",
    "checkpoint_dir = \"checkpoint\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
    "checkpoint_best_path = os.path.join(checkpoint_dir, \"checkpoint_best.pth\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"=> loading checkpoint '{}'\".format(checkpoint_path))\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    begin_epoch = checkpoint['epoch']\n",
    "    best_epoch = checkpoint['best_epoch']\n",
    "    best_test_monitor = checkpoint['best_test_monitor']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(checkpoint_path, begin_epoch))\n",
    "\n",
    "current_lr = lr\n",
    "# set_lr(optimizer, 1e-4)\n",
    "skip_first_epoch = False\n",
    "for epoch in range(begin_epoch, num_epoch):\n",
    "    current_lr = get_lr(optimizer)\n",
    "    print(f\"Epoch {epoch}|lr:{current_lr}|Memory: {mem():.2f} GB...\")\n",
    "    \n",
    "    if not skip_first_epoch or epoch > 0:\n",
    "        # training\n",
    "        model.train()\n",
    "        for train_data in tqdm(train_dataloader):\n",
    "            model_pred = model(train_data[0])\n",
    "            train_loss = loss_function(model_pred.view(-1, output_embed_dim), train_data[1].view(-1, output_embed_dim).cuda(non_blocking=True))\n",
    "\n",
    "            # loss and accuracy monitor\n",
    "            avg_loss.update(train_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(train_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-3))\n",
    "            avg_diff_ratio.update(diff_ratio)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_data in tqdm(test_dataloader):\n",
    "            model_pred = model(test_data[0])\n",
    "            test_loss = loss_function(model_pred.view(-1, output_embed_dim), test_data[1].view(-1, output_embed_dim).to(model_pred.device))\n",
    "            \n",
    "            # loss and accuracy monitor\n",
    "            avg_loss_test.update(test_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(test_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-3))\n",
    "            avg_diff_ratio_test.update(diff_ratio)\n",
    "    \n",
    "            # display some example\n",
    "            test_input_data_numpy = test_data[0].numpy()\n",
    "            current_batch_size = test_input_data_numpy.shape[0]\n",
    "            sample_idx = np.random.choice(current_batch_size, 2)\n",
    "            sample_input = decode_nn_data(test_input_data_numpy[sample_idx], is_input=True)\n",
    "            sample_raw_output = decode_nn_data(test_data[1].numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            sample_output = decode_nn_data(test_data[1].numpy()[sample_idx], is_input=False, apply_float=True)\n",
    "            sample_raw_pred = decode_nn_data(model_pred.cpu().detach().numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            sample_pred = decode_nn_data(model_pred.cpu().detach().numpy()[sample_idx], is_input=False, apply_float=True)\n",
    "            print(\"sample_input\", sample_input)\n",
    "            print(\"sample_raw_output\", sample_raw_output, \"sample_raw_pred\", sample_raw_pred)\n",
    "            print(\"sample_output\", sample_output, \"sample_pred\", sample_pred)\n",
    "\n",
    "    # update best_test_monitor\n",
    "    # test_monitor = avg_diff_ratio_test.val\n",
    "    test_monitor = avg_loss_test.val\n",
    "    if test_monitor != float(\"inf\") and test_monitor != float('nan') and test_monitor < best_test_monitor:\n",
    "        best_test_monitor = test_monitor\n",
    "        best_epoch = epoch + 1\n",
    "        patient_count = 0\n",
    "        \n",
    "        # save best checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_test_monitor': best_test_monitor,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, checkpoint_best_path)\n",
    "    else:\n",
    "        patient_count += 1\n",
    "\n",
    "    print(f\"[Epoch:{epoch}]|avg_loss:{avg_loss.val:.6f}|lr:{current_lr}|avg_diff_ratio:{avg_diff_ratio.val:.3f}|avg_loss_test:{avg_loss_test.val:.6f}|avg_diff_ratio_test:{avg_diff_ratio_test.val:.3f}|\"\n",
    "          f\"best_test_monitor:{best_test_monitor:.3f}|best_epoch:{best_epoch}|patient_count:{patient_count}/{lr_patience}|Memory: {mem():.2f} GB\")\n",
    "    \n",
    "    # update learning rate if needed\n",
    "    if epoch < warmup_epoch:\n",
    "        print(f\"warming up! increase learning rate from {current_lr:.8f} to {current_lr * warmup_factor:.8f}\")\n",
    "        set_lr(optimizer, current_lr * warmup_factor)\n",
    "        patient_count = 0\n",
    "    else:\n",
    "        if patient_count >= lr_patience and current_lr > lr_threshold:\n",
    "            print(f\"reach patient threshold! reducing learning rate from {current_lr:.8f} to {current_lr * lr_factor:.8f}\")\n",
    "            set_lr(optimizer, current_lr * lr_factor)\n",
    "            patient_count = 0\n",
    "    \n",
    "    # save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_test_monitor': best_test_monitor,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # reset variables\n",
    "    avg_loss.reset()\n",
    "    avg_loss_test.reset()\n",
    "    avg_diff_ratio.reset()\n",
    "    avg_diff_ratio_test.reset()\n",
    "    train_dataloader.dataset.refresh_data()\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c80cd1-329d-43ea-9a65-c4086e04f386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3132f025-57b8-4c26-8361-46967e82833e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n",
      "CUDA:0 _CudaDeviceProperties(name='NVIDIA GeForce GTX 1070', major=6, minor=1, total_memory=8105MB, multi_processor_count=15) [(8004.625, 8105.0625)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# logging jupiterlab notebook \n",
    "import logging\n",
    "nblog = open(\"nb.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "%autosave 60\n",
    "\n",
    "# GPU infos\n",
    "num_GPUs = torch.cuda.device_count()\n",
    "for i in range(num_GPUs):\n",
    "    info = torch.cuda.get_device_properties(i)\n",
    "    mem_info = torch.cuda.mem_get_info(i)\n",
    "    print(f\"CUDA:{i} {info} [{mem_info[0]/ 1024 ** 2, mem_info[1]/ 1024 ** 2}]\")\n",
    "\n",
    "# variables\n",
    "operators = ['-', '+', '*', '/']\n",
    "# operators = ['+', '-', '*']\n",
    "brackets = ['(', ')']\n",
    "input_chars = [\" \"] + [str(d) for d in range(10)] + [\".\"] + operators + brackets\n",
    "output_chars = [\" \"] + [str(d) for d in range(10)] + [\"-\", \".\"]\n",
    "max_number = 999\n",
    "max_digit = 5\n",
    "max_bracket = 3\n",
    "input_dim = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555245d4-25fb-4168-97fa-9685dcf126ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating simple arithematic equations and answers\n",
    "def generate_equation():\n",
    "    # number of numbers will be in the equation\n",
    "    num_digits = random.randint(2, max_digit)  # Choose a random number of digits for each operand\n",
    "\n",
    "    # Generate a list of elements in equation\n",
    "    equations = []\n",
    "    for i in range(num_digits):\n",
    "        equations.append(str(random.randint(0, max_number)))\n",
    "        if i < num_digits - 1:\n",
    "            equations.append(random.choice(operators))\n",
    "\n",
    "    # Add brackets randomly\n",
    "    num_brackets = random.randint(0, max_bracket)\n",
    "    for _ in range(num_brackets):\n",
    "        pos1 = random.randint(0, len(equations) - 1)\n",
    "        while equations[pos1] in operators + brackets:\n",
    "            pos1 += 1\n",
    "        new_equations = equations[:pos1] + ['('] + equations[pos1:]\n",
    "        \n",
    "        pos2 = random.randint(pos1 + 2, len(new_equations))\n",
    "        while 2 < pos2 < len(new_equations) and new_equations[pos2 - 1] in operators + brackets:\n",
    "            pos2 += 1\n",
    "        if pos2 == len(new_equations):\n",
    "            continue\n",
    "        new_equations = new_equations[:pos2] + [')'] + new_equations[pos2:]\n",
    "        equations = new_equations\n",
    "\n",
    "    # concatenate them into a single string\n",
    "    final_equation = \"\".join(equations)\n",
    "    return final_equation\n",
    "\n",
    "# evaluate the equation and get the result\n",
    "def evaluate_equation(equation):\n",
    "    try:\n",
    "        # result = f\"{{:.6f}}\".format(eval(equation)).zfill(input_dim)\n",
    "        # result = f\"{{:.6f}}\".format(eval(equation))\n",
    "        # result = str(int(round(eval(equation))))\n",
    "        result = str(eval(equation))\n",
    "        if \".\" in result or \"e\" in result:\n",
    "            result = f\"{{:.6f}}\".format(eval(equation))\n",
    "        return result\n",
    "    except ZeroDivisionError:\n",
    "        return \" \" * input_dim\n",
    "\n",
    "# function to generate a string equation with answer\n",
    "def generate_eq():\n",
    "    # Generate and evaluate a random equation\n",
    "    equation = generate_equation()\n",
    "    result = evaluate_equation(equation)\n",
    "    return equation, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d91eb00-3b10-440d-8671-ba2020ae13fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('797*262*((515*941))/118', '857579632.288136')\n",
      "('531-595', '-64')\n",
      "('(((388/87)/505)/33)-115', '-114.999732')\n",
      "('(360-217/477*534)-912', '-794.930818')\n",
      "('893-((831))-332', '-270')\n"
     ]
    }
   ],
   "source": [
    "# generate some examples\n",
    "for _ in range(5):\n",
    "    print(generate_eq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3025da8-7ac2-4a0b-b121-39304e6c48f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input string length: 25\n",
      "Max result string length: 25\n",
      "Min result string: -566161298386\n",
      "Max result string: 349340639127480\n",
      "Number of invalid input string: 67/100000 = 0.00067\n"
     ]
    }
   ],
   "source": [
    "# run the generation function many times to get the maxium length of the equation and maximum range of the answer\n",
    "num_trail = 100000\n",
    "max_len_eq = 0\n",
    "max_len_result = 0\n",
    "max_result = float(-np.inf)\n",
    "min_result = float(np.inf)\n",
    "max_result_str = None\n",
    "min_result_str = None\n",
    "invalid_count = 0\n",
    "for _ in range(num_trail):\n",
    "    equation, result = generate_eq()\n",
    "    if result != \" \" * input_dim:\n",
    "        fresult = float(result)\n",
    "        if fresult > max_result:\n",
    "            max_result = fresult\n",
    "            max_result_str = result\n",
    "        if fresult < min_result:\n",
    "            min_result = fresult\n",
    "            min_result_str = result\n",
    "    else:\n",
    "        invalid_count += 1\n",
    "    len_eq, len_result = len(equation), len(result)\n",
    "    max_len_eq = len_eq if len_eq > max_len_eq else max_len_eq\n",
    "    max_len_result = len_result if len_result > max_len_result else max_len_result\n",
    "\n",
    "print(f\"Max input string length: {max_len_eq}\")\n",
    "print(f\"Max result string length: {max_len_result}\")\n",
    "print(f\"Min result string: {min_result_str}\")\n",
    "print(f\"Max result string: {max_result_str}\")\n",
    "print(f\"Number of invalid input string: {invalid_count}/{num_trail} = {invalid_count/num_trail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e134e9-1d01-4b0d-9b9e-66b1a14f3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.', '-', '+', '*', '/', '(', ')'] input_embed_dim 18\n",
      "output_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '.'] output_embed_dim 13\n",
      "==========[input_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      ". [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "+ [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "* [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "/ [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "( [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      ") [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[output_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      ". [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[input_embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 .\n",
      "12 -\n",
      "13 +\n",
      "14 *\n",
      "15 /\n",
      "16 (\n",
      "17 )\n",
      "==========[output_embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 -\n",
      "12 .\n"
     ]
    }
   ],
   "source": [
    "# the embedding dimensions and mappings\n",
    "input_embed_dim = len(input_chars)\n",
    "output_embed_dim = len(output_chars)\n",
    "print(\"input_chars\", input_chars, \"input_embed_dim\", input_embed_dim)\n",
    "print(\"output_chars\", output_chars, \"output_embed_dim\", output_embed_dim)\n",
    "input_embed_map = {e: np.eye(input_embed_dim)[i] for i, e in enumerate(input_chars)}\n",
    "output_embed_map = {e: np.eye(output_embed_dim)[i] for i, e in enumerate(output_chars)}\n",
    "input_embed_inverse_map = {i: k for i, k in enumerate(input_embed_map.keys())}\n",
    "output_embed_inverse_map = {i: k for i, k in enumerate(output_embed_map.keys())}\n",
    "\n",
    "print(\"==========[input_embed_map]============\")\n",
    "for k in input_embed_map.keys():\n",
    "    print(k, input_embed_map[k])\n",
    "\n",
    "print(\"==========[output_embed_map]============\")\n",
    "for k in output_embed_map.keys():\n",
    "    print(k, output_embed_map[k])\n",
    "\n",
    "print(\"==========[input_embed_inverse_map]============\")\n",
    "for k in input_embed_inverse_map.keys():\n",
    "    print(k, input_embed_inverse_map[k])\n",
    "    \n",
    "print(\"==========[output_embed_inverse_map]============\")\n",
    "for k in output_embed_inverse_map.keys():\n",
    "    print(k, output_embed_inverse_map[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4562a51-d95a-4493-a419-e9514d465d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input data: [('(947)/907', '1.044101'), ('(309)*260-283', '80057')]\n",
      "raw input size: input=(2, 25, 18), output=(2, 25, 13)\n",
      "time_spent: 0.00036406517028808594s\n"
     ]
    }
   ],
   "source": [
    "# function to generate neural netowrk (nn) data for the Transformer\n",
    "def generate_nn_data(num_sample, outout_raw_data_pair=False):\n",
    "    data_pair = [generate_eq() for _ in range(num_sample)]\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for i in range(num_sample):\n",
    "        i_str = data_pair[i][0]\n",
    "        o_str = data_pair[i][1]\n",
    "        \n",
    "        i_vec = np.zeros((input_dim, input_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(reversed(i_str)):\n",
    "            i_vec[input_dim - i - 1] = input_embed_map[char]\n",
    "        input_data.append(i_vec)\n",
    "\n",
    "        j_vec = np.zeros((input_dim, output_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(reversed(o_str)):\n",
    "            j_vec[input_dim - i - 1] = output_embed_map[char]\n",
    "        output_data.append(j_vec)\n",
    "\n",
    "    input_data = np.array(input_data, dtype=np.float32)\n",
    "    output_data = np.array(output_data, dtype=np.float32)\n",
    "    if outout_raw_data_pair:\n",
    "        return input_data, output_data, data_pair\n",
    "    else:\n",
    "        return input_data, output_data\n",
    "\n",
    "time_start = time.time()\n",
    "input_data, output_data, data_pair = generate_nn_data(2, outout_raw_data_pair=True)\n",
    "time_spent = time.time() - time_start\n",
    "print(f\"raw input data: {data_pair}\")\n",
    "print(f\"raw input size: input={input_data.shape}, output={output_data.shape}\")\n",
    "print(f\"time_spent: {time_spent}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5819827-45b0-4f19-8d81-3687734080e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : ['                (947)/907', '            (309)*260-283']\n",
      "output: ['                 1.044101', '                    80057']\n"
     ]
    }
   ],
   "source": [
    "# function to decode the nn data back to string\n",
    "def decode_nn_data(output_nn_data, is_input, apply_float=False):\n",
    "    decoded_output = []\n",
    "    c_batchsize =  output_nn_data.shape[0]\n",
    "    c_slen =  output_nn_data.shape[1]\n",
    "    if is_input:\n",
    "        embed_inverse_map = input_embed_inverse_map\n",
    "    else:\n",
    "        embed_inverse_map = output_embed_inverse_map\n",
    "    for b in range(c_batchsize):\n",
    "        e_output = [embed_inverse_map[np.argmax(output_nn_data[b][s])] for s in range(c_slen)]\n",
    "        joint_e_output = \"\".join(e_output)\n",
    "        if apply_float:\n",
    "            try:\n",
    "                decoded_output.append(float(joint_e_output))\n",
    "            except:\n",
    "                decoded_output.append(0.0)\n",
    "        else:\n",
    "            decoded_output.append(joint_e_output)\n",
    "    return decoded_output\n",
    "print(f\"input : {decode_nn_data(input_data, is_input=True, apply_float=False)}\")\n",
    "print(f\"output: {decode_nn_data(output_data, is_input=False, apply_float=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b81ff04-5ed9-4d14-8ca5-0efe4ca75ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "input: ['     776/(41*988)/414*991', '            773-(633)*931'], output: ['                 0.045856', '                  -588550']\n",
      "input size: torch.Size([2, 25, 18]), output size: torch.Size([2, 25, 13])\n",
      "input: ['                  920*483', '        444*625+(989)/453'], output: ['                   444360', '            277502.183223']\n",
      "input size: torch.Size([2, 25, 18]), output size: torch.Size([2, 25, 13])\n",
      "input: ['                  736/727', '      847*249*720-195+244'], output: ['                 1.012380', '                151850209']\n",
      "input size: torch.Size([2, 25, 18]), output size: torch.Size([2, 25, 13])\n"
     ]
    }
   ],
   "source": [
    "# our custom pytorch dataset class\n",
    "class CustomDataset(data_utils.Dataset):\n",
    "    def __init__(self, num_sample, random_seed=0):\n",
    "        random.seed(0)\n",
    "        self.num_sample = num_sample\n",
    "        self.refresh_data()\n",
    "\n",
    "    def refresh_data(self):\n",
    "        print(\"refreshing dataset...\")\n",
    "        self.input_data, self.output_data = generate_nn_data(self.num_sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.output_data[idx]\n",
    "\n",
    "train_dataset = CustomDataset(6)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=2)\n",
    "for i in train_dataloader:\n",
    "    print(f\"input: {decode_nn_data(i[0].numpy(), is_input=True)}, output: {decode_nn_data(i[1].numpy(), is_input=False)}\")\n",
    "    print(f\"input size: {i[0].shape}, output size: {i[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62568ee-b33a-4c72-96cb-98be9069c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes and functions for our basic Transformer model\n",
    "class SwiGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        return F.silu(gate) * x\n",
    "\n",
    "class MyActF(nn.Module):\n",
    "    def __init__(self, mode=\"silu\"):\n",
    "        super().__init__()\n",
    "        if mode == \"leaky_relu\":\n",
    "            self.act_f = nn.LeakyReLU(negative_slope=0.01)\n",
    "        elif mode == \"relu\":\n",
    "            self.act_f = nn.ReLU()\n",
    "        elif mode == \"gelu\":\n",
    "            self.act_f = nn.GELU()\n",
    "        elif mode in [\"silu\", \"swish\"]:\n",
    "            self.act_f = nn.SiLU()\n",
    "        elif mode == \"hardswish\":\n",
    "            self.act_f = nn.Hardswish()\n",
    "        elif mode == \"SwiGLU\":\n",
    "            self.act_f = SwiGLU()\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act_f(x)\n",
    "\n",
    "\n",
    "class BatchRenorm(torch.jit.ScriptModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        eps: float = 1e-3,\n",
    "        momentum: float = 0.01,\n",
    "        affine: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"running_std\", torch.ones(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"num_batches_tracked\", torch.tensor(0, dtype=torch.long))\n",
    "        self.weight = torch.nn.Parameter(torch.ones(num_features, dtype=torch.float))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(num_features, dtype=torch.float))\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        self.step = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        raise NotImplementedError()  # pragma: no cover\n",
    "\n",
    "    @property\n",
    "    def rmax(self) -> torch.Tensor:\n",
    "        return (2 / 35000 * self.num_batches_tracked + 25 / 35).clamp_(1.0, 3.0)\n",
    "\n",
    "    @property\n",
    "    def dmax(self) -> torch.Tensor:\n",
    "        return (5 / 20000 * self.num_batches_tracked - 25 / 20).clamp_(0.0, 5.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self._check_input_dim(x)\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        if self.training:\n",
    "            dims = [i for i in range(x.dim() - 1)]\n",
    "            batch_mean = x.mean(dims)\n",
    "            batch_std = x.std(dims, unbiased=False) + self.eps\n",
    "            r = (batch_std.detach() / self.running_std.view_as(batch_std)).clamp_(1 / self.rmax, self.rmax)\n",
    "            d = ((batch_mean.detach() - self.running_mean.view_as(batch_mean)) / self.running_std.view_as(batch_std)).clamp_(-self.dmax, self.dmax)\n",
    "            x = (x - batch_mean) / batch_std * r + d\n",
    "            self.running_mean += self.momentum * (batch_mean.detach() - self.running_mean)\n",
    "            self.running_std += self.momentum * (batch_std.detach() - self.running_std)\n",
    "            self.num_batches_tracked += 1\n",
    "        else:\n",
    "            x = (x - self.running_mean) / self.running_std\n",
    "        if self.affine:\n",
    "            x = self.weight * x + self.bias\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BatchRenorm1d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() not in [2, 3]:\n",
    "            raise ValueError(\"expected 2D or 3D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm2d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(\"expected 4D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm3d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 5:\n",
    "            raise ValueError(\"expected 5D input (got {x.dim()}D input)\")\n",
    "\n",
    "class MyNorm(nn.Module):\n",
    "    def __init__(self, input_dim, mode=\"BatchNorm\"):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        if mode == \"LayerNorm\":\n",
    "            self.norm = nn.LayerNorm(input_dim)\n",
    "        elif mode == \"BatchNorm\":\n",
    "            self.norm = nn.BatchNorm1d(input_dim)\n",
    "        elif mode == \"BatchRenorm\":\n",
    "            self.norm = BatchRenorm1d(input_dim)\n",
    "        elif mode == \"GroupNorm\":\n",
    "            self.num_groups = 8\n",
    "            self.remainder_dim = None\n",
    "            self.rounded_input_dim = None\n",
    "            if self.num_groups > input_dim:\n",
    "                self.num_groups = 1\n",
    "                self.remainder_dim = 0\n",
    "                self.rounded_input_dim = input_dim\n",
    "            else:\n",
    "                self.remainder_dim = input_dim % self.num_groups\n",
    "                self.rounded_input_dim = input_dim - self.remainder_dim\n",
    "            self.norm = nn.GroupNorm(self.num_groups, self.rounded_input_dim)\n",
    "            if self.remainder_dim > 0:\n",
    "                self.remainder_norm = nn.LayerNorm(self.remainder_dim)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == \"GroupNorm\":\n",
    "            if self.remainder_dim == 0:\n",
    "                self.norm(x)\n",
    "            else:\n",
    "                split_x1, split_x2 = torch.split(x, [self.rounded_input_dim, self.remainder_dim])\n",
    "                norm_x1 = self.norm(split_x1)\n",
    "                norm_x2 = self.remainder_norm(split_x2)\n",
    "                return torch.cat([norm_x1, norm_x2], -1)\n",
    "        else:\n",
    "            return self.norm(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, token_dim: int, dropout: float = 0.0, max_len: int = 5000, learnable: bool = False):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.learnable = learnable\n",
    "        if self.learnable:\n",
    "            self.pe = nn.Parameter(torch.normal(mean=0, std=0.001, size=(1, max_len, token_dim)))\n",
    "        else:\n",
    "            position = torch.arange(max_len).unsqueeze(1)\n",
    "            div_term = torch.exp(torch.arange(0, token_dim, 2) * (-math.log(10000.0) / token_dim))\n",
    "            pe = torch.zeros(1, max_len, token_dim)\n",
    "            pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "            pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "            self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MyTransformerEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_token_dim=64,\n",
    "                 output_token_dim=16,\n",
    "                 num_token=20,\n",
    "                 nhead=16,\n",
    "                 dim_feedforward=256,\n",
    "                 dropout=0.1,\n",
    "                 activation='gelu',\n",
    "                 nlayers=3,\n",
    "                 positional_encoding=True,\n",
    "                 proj_norm_mode=\"LayerNorm\",\n",
    "                 ):\n",
    "        super(MyTransformerEncoder, self).__init__()\n",
    "        self.input_token_dim = input_token_dim\n",
    "        self.output_token_dim = output_token_dim\n",
    "        self.num_token = num_token\n",
    "        self.positional_encoding = positional_encoding\n",
    "        if input_token_dim % 2 == 0:\n",
    "            self.corrected_input_token_dim = input_token_dim\n",
    "        else:\n",
    "            self.corrected_input_token_dim = input_token_dim + 1\n",
    "        self.transformer_pre_projection = nn.Sequential(\n",
    "            nn.Linear(self.input_token_dim, self.corrected_input_token_dim, bias=False),\n",
    "            MyNorm(self.corrected_input_token_dim, mode=proj_norm_mode),\n",
    "            MyActF(activation),\n",
    "            nn.Linear(self.corrected_input_token_dim, self.corrected_input_token_dim, bias=False),\n",
    "            MyNorm(self.corrected_input_token_dim, mode=proj_norm_mode),\n",
    "            MyActF(activation),\n",
    "        )\n",
    "        if positional_encoding:\n",
    "            self.pos_encoder = PositionalEncoding(token_dim=self.corrected_input_token_dim, dropout=0.0, max_len=num_token, learnable=False)\n",
    "        else:\n",
    "            self.pos_encoder = None\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.corrected_input_token_dim,\n",
    "                                                   nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation=activation,\n",
    "                                                   batch_first=True,\n",
    "                                                   norm_first=True,)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.transformer_final_projection = nn.Sequential(\n",
    "            nn.Linear(self.corrected_input_token_dim, self.output_token_dim, bias=True),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, num_token, input_token_dim]\n",
    "        output:\n",
    "            y: Tensor, shape [batch_size, num_token, output_token_dim]\n",
    "        \"\"\"\n",
    "        bs, t, d = x.size(0), x.size(1), x.size(2)\n",
    "        assert d == self.input_token_dim\n",
    "        \n",
    "        x_t = x.view(bs * t, d).contiguous()\n",
    "        proj_x = self.transformer_pre_projection(x_t)  # [batch_size, num_token, input_token_dim]\n",
    "        proj_x_t = proj_x.view(bs, t, self.corrected_input_token_dim).contiguous()\n",
    "        \n",
    "        # proj_x_t = x\n",
    "        \n",
    "        if self.positional_encoding:\n",
    "            endcoded_x = self.pos_encoder(proj_x_t)\n",
    "        else:\n",
    "            endcoded_x = proj_x_t\n",
    "        transformed_x = self.transformer_encoder(endcoded_x)\n",
    "        transformed_x_t = transformed_x.view(bs * t, self.corrected_input_token_dim).contiguous()\n",
    "        proj_transformed_x = self.transformer_final_projection(transformed_x_t).view(bs, t, self.output_token_dim).contiguous()\n",
    "        return proj_transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6a3802-81a7-4fff-8d4e-4557be38346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "\n",
    "# a simple average meter class for monitoring averages\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.min = float(np.inf)\n",
    "        self.max = float(-np.inf)\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count if self.count != 0 else 0\n",
    "        self.min = val if val < self.min else self.min\n",
    "        self.max = val if val > self.max else self.max\n",
    "        \n",
    "# function to get memory usage\n",
    "def mem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 ** 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73168104-64bb-44b1-81d8-1906d30fa45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "refreshing dataset...\n"
     ]
    }
   ],
   "source": [
    "# training variables\n",
    "num_epoch = 1000\n",
    "batch_size = 500\n",
    "test_batch_size = batch_size * 4\n",
    "num_of_sample_per_epoch = batch_size * 2500\n",
    "num_of_test_sample = 10000\n",
    "lr = 1e-2\n",
    "wd = 0.001\n",
    "lr_factor = 0.1\n",
    "lr_patience = 5\n",
    "lr_threshold = lr * 1e-3\n",
    "warmup_epoch = 0\n",
    "warmup_factor = 5.0**(1.0/warmup_epoch) if warmup_epoch > 0 else 1.0\n",
    "GPUs = list(range(num_GPUs))\n",
    "\n",
    "# datasets\n",
    "train_dataset = CustomDataset(num_of_sample_per_epoch)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = CustomDataset(num_of_test_sample, random_seed=1234567890)\n",
    "test_dataloader = data_utils.DataLoader(test_dataset, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e3606b-45fc-4129-b893-b74bda3220f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxchu/miniconda3/envs/tfcal_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = MyTransformerEncoder(\n",
    "    input_token_dim=input_embed_dim,\n",
    "    output_token_dim=output_embed_dim,\n",
    "    num_token=input_dim,\n",
    "    nhead=6,\n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.1,\n",
    "    activation='gelu',\n",
    "    nlayers=32,\n",
    "    positional_encoding=True,\n",
    "    proj_norm_mode=\"LayerNorm\", # LayerNorm BatchNorm\n",
    ")\n",
    "model = torch.nn.DataParallel(model, device_ids=GPUs).cuda()\n",
    "\n",
    "# optimizer\n",
    "train_parameters = model.parameters()\n",
    "optimizer = torch.optim.AdamW(train_parameters, lr=lr, weight_decay=wd)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer,\n",
    "#     mode='min',\n",
    "#     factor=lr_factor,\n",
    "#     patience=lr_patience,\n",
    "#     threshold=lr_threshold,\n",
    "#     threshold_mode='rel')\n",
    "\n",
    "# loss\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, mode):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == \"CrossEntropy\":\n",
    "            self.loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
    "        elif self.mode == \"MSE\":\n",
    "            self.loss_function = nn.MSELoss(reduction='mean')\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, model_pred, target):\n",
    "        batch_size = model_pred.size(0)\n",
    "        n_token = model_pred.size(1)\n",
    "        token_dim = model_pred.size(2)\n",
    "        t_model_pred = model_pred.view(-1, token_dim)\n",
    "        t_target = target.view(-1, token_dim).cuda(non_blocking=True)\n",
    "        if self.mode == \"CrossEntropy\":\n",
    "            target_indices = torch.argmax(t_target, dim=-1)\n",
    "            loss = self.loss_function(t_model_pred, target_indices)\n",
    "        elif self.mode == \"MSE\":\n",
    "            loss = self.loss_function(t_model_pred, t_target)\n",
    "        return loss\n",
    "loss_function = CustomLoss(\"CrossEntropy\").cuda()\n",
    "\n",
    "# helper functions\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def set_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5e43a-8714-46bb-9a4b-81d74e30e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0|lr:0.01|Memory: 7.89 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e27b5aec3940928020a0ead8b0db35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# monitoring variables\n",
    "begin_epoch = 0\n",
    "avg_loss = AverageMeter()\n",
    "avg_loss_test = AverageMeter()\n",
    "avg_diff_ratio = AverageMeter()\n",
    "avg_diff_ratio_test = AverageMeter()\n",
    "best_test_monitor = float(np.inf)\n",
    "best_epoch = 0\n",
    "patient_count = 0\n",
    "\n",
    "# checkpoint paths\n",
    "checkpoint_dir = \"checkpoint\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
    "checkpoint_best_path = os.path.join(checkpoint_dir, \"checkpoint_best.pth\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"=> loading checkpoint '{}'\".format(checkpoint_path))\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    begin_epoch = checkpoint['epoch']\n",
    "    best_epoch = checkpoint['best_epoch']\n",
    "    best_test_monitor = checkpoint['best_test_monitor']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(checkpoint_path, begin_epoch))\n",
    "\n",
    "current_lr = lr\n",
    "# set_lr(optimizer, 1e-4)\n",
    "skip_first_epoch = False\n",
    "for epoch in range(begin_epoch, num_epoch):\n",
    "    current_lr = get_lr(optimizer)\n",
    "    print(f\"Epoch {epoch}|lr:{current_lr}|Memory: {mem():.2f} GB...\")\n",
    "    \n",
    "    if not skip_first_epoch or epoch > 0:\n",
    "        # training\n",
    "        model.train()\n",
    "        for train_data in tqdm(train_dataloader):\n",
    "            model_pred = model(train_data[0])\n",
    "            train_loss = loss_function(model_pred, train_data[1])\n",
    "\n",
    "            # loss and accuracy monitor\n",
    "            avg_loss.update(train_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(train_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-6))\n",
    "            avg_diff_ratio.update(diff_ratio)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_data in tqdm(test_dataloader):\n",
    "            model_pred = model(test_data[0])\n",
    "            test_loss = loss_function(model_pred, test_data[1])\n",
    "            \n",
    "            # loss and accuracy monitor\n",
    "            avg_loss_test.update(test_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(test_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-6))\n",
    "            avg_diff_ratio_test.update(diff_ratio)\n",
    "    \n",
    "            # display some example\n",
    "            display_size = 2\n",
    "            test_input_data_numpy = test_data[0].numpy()\n",
    "            current_batch_size = test_input_data_numpy.shape[0]\n",
    "            sample_idx = np.random.choice(current_batch_size, display_size)\n",
    "            sample_input = decode_nn_data(test_input_data_numpy[sample_idx], is_input=True)\n",
    "            \n",
    "            sample_raw_output = decode_nn_data(test_data[1].numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            sample_raw_pred = decode_nn_data(model_pred.cpu().detach().numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            \n",
    "            sample_output = gt_result[sample_idx]\n",
    "            sample_pred = pred_result[sample_idx]\n",
    "            \n",
    "            for i  in range(display_size):\n",
    "                print(f\"test string #{sample_idx[i]:>5}: {sample_input[i]:>20}|raw gt: {sample_raw_output[i]:>20}|raw prediction: {sample_raw_pred[i]:>20}|prediction(float): {sample_pred[i]:>20.6f}\")\n",
    "\n",
    "    # update best_test_monitor\n",
    "    # test_monitor = avg_diff_ratio_test.avg\n",
    "    test_monitor = avg_loss_test.avg\n",
    "    if test_monitor != float(\"inf\") and test_monitor != float('nan') and test_monitor < best_test_monitor:\n",
    "        best_test_monitor = test_monitor\n",
    "        best_epoch = epoch + 1\n",
    "        patient_count = 0\n",
    "        \n",
    "        # save best checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_test_monitor': best_test_monitor,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, checkpoint_best_path)\n",
    "    else:\n",
    "        patient_count += 1\n",
    "\n",
    "    print(f\"[Epoch:{epoch}]|lr:{current_lr:.8f}|avg_loss:{avg_loss.avg:.6f}|avg_diff_ratio:{avg_diff_ratio.avg:.3f}|avg_loss_test:{avg_loss_test.avg:.6f}|avg_diff_ratio_test:{avg_diff_ratio_test.avg:.3f}|\"\n",
    "          f\"best_test_monitor:{best_test_monitor:.3f}|best_epoch:{best_epoch}|patient_count:{patient_count}/{lr_patience}|Memory: {mem():.2f} GB\")\n",
    "    \n",
    "    # update learning rate if needed\n",
    "    if epoch < warmup_epoch:\n",
    "        print(f\"warming up! increase learning rate from {current_lr:.8f} to {current_lr * warmup_factor:.8f}\")\n",
    "        set_lr(optimizer, current_lr * warmup_factor)\n",
    "        patient_count = 0\n",
    "    else:\n",
    "        if patient_count >= lr_patience:\n",
    "            print(f\"reach patient threshold! reducing learning rate from {current_lr:.8f} to {current_lr * lr_factor:.8f}\")\n",
    "            set_lr(optimizer, current_lr * lr_factor)\n",
    "            patient_count = 0\n",
    "    \n",
    "    # save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_test_monitor': best_test_monitor,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # reset variables\n",
    "    avg_loss.reset()\n",
    "    avg_loss_test.reset()\n",
    "    avg_diff_ratio.reset()\n",
    "    avg_diff_ratio_test.reset()\n",
    "    train_dataloader.dataset.refresh_data()\n",
    "    \n",
    "    if current_lr < lr_threshold:\n",
    "        print(f\"reading learning rate threshold: {lr_threshold}!\")\n",
    "        break\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c80cd1-329d-43ea-9a65-c4086e04f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_test(model, num_sample):\n",
    "    input_data, output_data, data_pair = generate_nn_data(num_sample, outout_raw_data_pair=True)\n",
    "    model_pred = model(torch.Tensor(input_data))\n",
    "    results = decode_nn_data(model_pred.detach().cpu().numpy(), is_input=False, apply_float=True)\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"input string: {data_pair[i][0]:>20}|gt: {data_pair[i][1]:>20}|prediction: {result:>20}\")\n",
    "    \n",
    "model_inference_test(model, 5)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77710b-a998-4c01-9b64-8e82444b3152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

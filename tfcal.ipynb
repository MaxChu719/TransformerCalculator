{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3132f025-57b8-4c26-8361-46967e82833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA:0 _CudaDeviceProperties(name='NVIDIA GeForce GTX 1070', major=6, minor=1, total_memory=8105MB, multi_processor_count=15) [(8004.625, 8105.0625)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# logging jupiterlab notebook \n",
    "import logging\n",
    "nblog = open(\"nb.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# GPU infos\n",
    "num_GPUs = torch.cuda.device_count()\n",
    "for i in range(num_GPUs):\n",
    "    info = torch.cuda.get_device_properties(i)\n",
    "    mem_info = torch.cuda.mem_get_info(i)\n",
    "    print(f\"CUDA:{i} {info} [{mem_info[0]/ 1024 ** 2, mem_info[1]/ 1024 ** 2}]\")\n",
    "\n",
    "# variables\n",
    "# operators = ['-', '+', '*', '/']\n",
    "operators = ['+', '-', '*']\n",
    "brackets = ['(', ')']\n",
    "input_chars = [\" \"] + [str(d) for d in range(10)] + [\".\"] + operators + brackets\n",
    "output_chars = [\" \"] + [str(d) for d in range(10)] + [\"-\"]\n",
    "max_number = 999\n",
    "max_digit = 5\n",
    "max_bracket = 3\n",
    "input_dim = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555245d4-25fb-4168-97fa-9685dcf126ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating simple arithematic equations and answers\n",
    "def generate_equation():\n",
    "    # number of numbers will be in the equation\n",
    "    num_digits = random.randint(2, max_digit)  # Choose a random number of digits for each operand\n",
    "\n",
    "    # Generate a list of elements in equation\n",
    "    equations = []\n",
    "    for i in range(num_digits):\n",
    "        equations.append(str(random.randint(0, max_number)))\n",
    "        if i < num_digits - 1:\n",
    "            equations.append(random.choice(operators))\n",
    "\n",
    "    # Add brackets randomly\n",
    "    num_brackets = random.randint(0, max_bracket)\n",
    "    for _ in range(num_brackets):\n",
    "        pos1 = random.randint(0, len(equations) - 1)\n",
    "        while equations[pos1] in operators + brackets:\n",
    "            pos1 += 1\n",
    "        new_equations = equations[:pos1] + ['('] + equations[pos1:]\n",
    "        \n",
    "        pos2 = random.randint(pos1 + 2, len(new_equations))\n",
    "        while 2 < pos2 < len(new_equations) and new_equations[pos2 - 1] in operators + brackets:\n",
    "            pos2 += 1\n",
    "        if pos2 == len(new_equations):\n",
    "            continue\n",
    "        new_equations = new_equations[:pos2] + [')'] + new_equations[pos2:]\n",
    "        equations = new_equations\n",
    "\n",
    "    # concatenate them into a single string\n",
    "    final_equation = \"\".join(equations)\n",
    "    return final_equation\n",
    "\n",
    "# evaluate the equation and get the result\n",
    "def evaluate_equation(equation):\n",
    "    try:\n",
    "        # result = f\"{{:.6f}}\".format(eval(equation)).zfill(input_dim)\n",
    "        result = str(eval(equation))\n",
    "        return result\n",
    "    except ZeroDivisionError:\n",
    "        return \" \" * input_dim\n",
    "\n",
    "# function to generate a string equation with answer\n",
    "def generate_eq():\n",
    "    # Generate and evaluate a random equation\n",
    "    equation = generate_equation()\n",
    "    result = evaluate_equation(equation)\n",
    "    return equation, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d91eb00-3b10-440d-8671-ba2020ae13fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('704-951-812', '-1059')\n",
      "('814+255-273*229-286', '-61734')\n",
      "('344*292*231', '23203488')\n",
      "('954+919', '1873')\n",
      "('951-935-825*793', '-654209')\n"
     ]
    }
   ],
   "source": [
    "# generate some examples\n",
    "for _ in range(5):\n",
    "    print(generate_eq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3025da8-7ac2-4a0b-b121-39304e6c48f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input string length: 25\n",
      "Max result string length: 15\n",
      "Min result string: -509012068312\n",
      "Max result string: 353452949813568\n",
      "Number of invalid input string: 0/100000 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# run the generation function many times to get the maxium length of the equation and maximum range of the answer\n",
    "num_trail = 100000\n",
    "max_len_eq = 0\n",
    "max_len_result = 0\n",
    "max_result = float(-np.inf)\n",
    "min_result = float(np.inf)\n",
    "max_result_str = None\n",
    "min_result_str = None\n",
    "invalid_count = 0\n",
    "for _ in range(num_trail):\n",
    "    equation, result = generate_eq()\n",
    "    if \"!\" not in result:\n",
    "        fresult = float(result)\n",
    "        if fresult > max_result:\n",
    "            max_result = fresult\n",
    "            max_result_str = result\n",
    "        if fresult < min_result:\n",
    "            min_result = fresult\n",
    "            min_result_str = result\n",
    "    else:\n",
    "        invalid_count += 1\n",
    "    len_eq, len_result = len(equation), len(result)\n",
    "    max_len_eq = len_eq if len_eq > max_len_eq else max_len_eq\n",
    "    max_len_result = len_result if len_result > max_len_result else max_len_result\n",
    "\n",
    "print(f\"Max input string length: {max_len_eq}\")\n",
    "print(f\"Max result string length: {max_len_result}\")\n",
    "print(f\"Min result string: {min_result_str}\")\n",
    "print(f\"Max result string: {max_result_str}\")\n",
    "print(f\"Number of invalid input string: {invalid_count}/{num_trail} = {invalid_count/num_trail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e134e9-1d01-4b0d-9b9e-66b1a14f3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.', '+', '-', '*', '(', ')'] input_embed_dim 17\n",
      "output_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'] output_embed_dim 12\n",
      "==========[input_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      ". [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "+ [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "* [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "( [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      ") [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[output_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 .\n",
      "12 +\n",
      "13 -\n",
      "14 *\n",
      "15 (\n",
      "16 )\n",
      "==========[embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 -\n"
     ]
    }
   ],
   "source": [
    "# the embedding dimensions and mappings\n",
    "input_embed_dim = len(input_chars)\n",
    "output_embed_dim = len(output_chars)\n",
    "print(\"input_chars\", input_chars, \"input_embed_dim\", input_embed_dim)\n",
    "print(\"output_chars\", output_chars, \"output_embed_dim\", output_embed_dim)\n",
    "input_embed_map = {e: np.eye(input_embed_dim)[i] for i, e in enumerate(input_chars)}\n",
    "output_embed_map = {e: np.eye(output_embed_dim)[i] for i, e in enumerate(output_chars)}\n",
    "input_embed_inverse_map = {i: k for i, k in enumerate(input_embed_map.keys())}\n",
    "output_embed_inverse_map = {i: k for i, k in enumerate(output_embed_map.keys())}\n",
    "\n",
    "print(\"==========[input_embed_map]============\")\n",
    "for k in input_embed_map.keys():\n",
    "    print(k, input_embed_map[k])\n",
    "\n",
    "print(\"==========[output_embed_map]============\")\n",
    "for k in output_embed_map.keys():\n",
    "    print(k, output_embed_map[k])\n",
    "\n",
    "print(\"==========[embed_inverse_map]============\")\n",
    "for k in input_embed_inverse_map.keys():\n",
    "    print(k, input_embed_inverse_map[k])\n",
    "    \n",
    "print(\"==========[embed_inverse_map]============\")\n",
    "for k in output_embed_inverse_map.keys():\n",
    "    print(k, output_embed_inverse_map[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4562a51-d95a-4493-a419-e9514d465d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input data: [('346*607', '210022'), ('754*373', '281242')]\n",
      "raw input size: input=(2, 25, 17), output=(2, 25, 12)\n",
      "time_spent: 0.00046372413635253906s\n"
     ]
    }
   ],
   "source": [
    "# function to generate neural netowrk (nn) data for the Transformer\n",
    "def generate_nn_data(num_sample, outout_raw_data_pair=False):\n",
    "    data_pair = [generate_eq() for _ in range(num_sample)]\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for i in range(num_sample):\n",
    "        i_str = data_pair[i][0]\n",
    "        o_str = data_pair[i][1]\n",
    "        \n",
    "        i_vec = np.zeros((input_dim, input_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(i_str):\n",
    "            i_vec[i] = input_embed_map[char]\n",
    "        input_data.append(i_vec)\n",
    "\n",
    "        j_vec = np.zeros((input_dim, output_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(o_str):\n",
    "            j_vec[i] = output_embed_map[char]\n",
    "        output_data.append(j_vec)\n",
    "\n",
    "    input_data = np.array(input_data, dtype=np.float32)\n",
    "    output_data = np.array(output_data, dtype=np.float32)\n",
    "    if outout_raw_data_pair:\n",
    "        return input_data, output_data, data_pair\n",
    "    else:\n",
    "        return input_data, output_data\n",
    "\n",
    "time_start = time.time()\n",
    "input_data, output_data, data_pair = generate_nn_data(2, outout_raw_data_pair=True)\n",
    "time_spent = time.time() - time_start\n",
    "print(f\"raw input data: {data_pair}\")\n",
    "print(f\"raw input size: input={input_data.shape}, output={output_data.shape}\")\n",
    "print(f\"time_spent: {time_spent}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5819827-45b0-4f19-8d81-3687734080e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : ['346*607                  ', '754*373                  ']\n",
      "output: ['210022                   ', '281242                   ']\n"
     ]
    }
   ],
   "source": [
    "# function to decode the nn data back to string\n",
    "def decode_nn_data(output_nn_data, is_input, apply_float=False):\n",
    "    decoded_output = []\n",
    "    c_batchsize =  output_nn_data.shape[0]\n",
    "    c_slen =  output_nn_data.shape[1]\n",
    "    if is_input:\n",
    "        embed_inverse_map = input_embed_inverse_map\n",
    "    else:\n",
    "        embed_inverse_map = output_embed_inverse_map\n",
    "    for b in range(c_batchsize):\n",
    "        e_output = [embed_inverse_map[np.argmax(output_nn_data[b][s])] for s in range(c_slen)]\n",
    "        joint_e_output = \"\".join(e_output)\n",
    "        if apply_float:\n",
    "            try:\n",
    "                decoded_output.append(float(joint_e_output))\n",
    "            except:\n",
    "                decoded_output.append(0.0)\n",
    "        else:\n",
    "            decoded_output.append(joint_e_output)\n",
    "    return decoded_output\n",
    "print(f\"input : {decode_nn_data(input_data, is_input=True, apply_float=False)}\")\n",
    "print(f\"output: {decode_nn_data(output_data, is_input=False, apply_float=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b81ff04-5ed9-4d14-8ca5-0efe4ca75ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "input: ['776-41-988*497-940       ', '288+(773)+633            '], output: ['-491241                  ', '1694                     ']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n",
      "input: ['920*338                  ', '453*266+824*((937))+95   '], output: ['310960                   ', '892681                   ']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n",
      "input: ['939*227+822              ', '82-896                   '], output: ['213975                   ', '-814                     ']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n"
     ]
    }
   ],
   "source": [
    "# our custom pytorch dataset class\n",
    "class CustomDataset(data_utils.Dataset):\n",
    "    def __init__(self, num_sample, random_seed=0):\n",
    "        random.seed(0)\n",
    "        self.num_sample = num_sample\n",
    "        self.refresh_data()\n",
    "\n",
    "    def refresh_data(self):\n",
    "        print(\"refreshing dataset...\")\n",
    "        self.input_data, self.output_data = generate_nn_data(self.num_sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.output_data[idx]\n",
    "\n",
    "train_dataset = CustomDataset(6)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=2)\n",
    "for i in train_dataloader:\n",
    "    print(f\"input: {decode_nn_data(i[0].numpy(), is_input=True)}, output: {decode_nn_data(i[1].numpy(), is_input=False)}\")\n",
    "    print(f\"input size: {i[0].shape}, output size: {i[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62568ee-b33a-4c72-96cb-98be9069c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes and functions for our basic Transformer model\n",
    "class SwiGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        return F.silu(gate) * x\n",
    "\n",
    "class MyActF(nn.Module):\n",
    "    def __init__(self, mode=\"silu\"):\n",
    "        super().__init__()\n",
    "        if mode == \"leaky_relu\":\n",
    "            self.act_f = nn.LeakyReLU(negative_slope=0.01)\n",
    "        elif mode == \"relu\":\n",
    "            self.act_f = nn.ReLU()\n",
    "        elif mode == \"gelu\":\n",
    "            self.act_f = nn.GELU()\n",
    "        elif mode in [\"silu\", \"swish\"]:\n",
    "            self.act_f = nn.SiLU()\n",
    "        elif mode == \"hardswish\":\n",
    "            self.act_f = nn.Hardswish()\n",
    "        elif mode == \"SwiGLU\":\n",
    "            self.act_f = SwiGLU()\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act_f(x)\n",
    "\n",
    "\n",
    "class BatchRenorm(torch.jit.ScriptModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        eps: float = 1e-3,\n",
    "        momentum: float = 0.01,\n",
    "        affine: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"running_std\", torch.ones(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"num_batches_tracked\", torch.tensor(0, dtype=torch.long))\n",
    "        self.weight = torch.nn.Parameter(torch.ones(num_features, dtype=torch.float))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(num_features, dtype=torch.float))\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        self.step = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        raise NotImplementedError()  # pragma: no cover\n",
    "\n",
    "    @property\n",
    "    def rmax(self) -> torch.Tensor:\n",
    "        return (2 / 35000 * self.num_batches_tracked + 25 / 35).clamp_(1.0, 3.0)\n",
    "\n",
    "    @property\n",
    "    def dmax(self) -> torch.Tensor:\n",
    "        return (5 / 20000 * self.num_batches_tracked - 25 / 20).clamp_(0.0, 5.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self._check_input_dim(x)\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        if self.training:\n",
    "            dims = [i for i in range(x.dim() - 1)]\n",
    "            batch_mean = x.mean(dims)\n",
    "            batch_std = x.std(dims, unbiased=False) + self.eps\n",
    "            r = (batch_std.detach() / self.running_std.view_as(batch_std)).clamp_(1 / self.rmax, self.rmax)\n",
    "            d = ((batch_mean.detach() - self.running_mean.view_as(batch_mean)) / self.running_std.view_as(batch_std)).clamp_(-self.dmax, self.dmax)\n",
    "            x = (x - batch_mean) / batch_std * r + d\n",
    "            self.running_mean += self.momentum * (batch_mean.detach() - self.running_mean)\n",
    "            self.running_std += self.momentum * (batch_std.detach() - self.running_std)\n",
    "            self.num_batches_tracked += 1\n",
    "        else:\n",
    "            x = (x - self.running_mean) / self.running_std\n",
    "        if self.affine:\n",
    "            x = self.weight * x + self.bias\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BatchRenorm1d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() not in [2, 3]:\n",
    "            raise ValueError(\"expected 2D or 3D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm2d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(\"expected 4D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm3d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 5:\n",
    "            raise ValueError(\"expected 5D input (got {x.dim()}D input)\")\n",
    "\n",
    "class MyNorm(nn.Module):\n",
    "    def __init__(self, input_dim, mode=\"BatchNorm\"):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        if mode == \"LayerNorm\":\n",
    "            self.norm = nn.LayerNorm(input_dim)\n",
    "        elif mode == \"BatchNorm\":\n",
    "            self.norm = nn.BatchNorm1d(input_dim)\n",
    "        elif mode == \"BatchRenorm\":\n",
    "            self.norm = BatchRenorm1d(input_dim)\n",
    "        elif mode == \"GroupNorm\":\n",
    "            self.num_groups = 8\n",
    "            self.remainder_dim = None\n",
    "            self.rounded_input_dim = None\n",
    "            if self.num_groups > input_dim:\n",
    "                self.num_groups = 1\n",
    "                self.remainder_dim = 0\n",
    "                self.rounded_input_dim = input_dim\n",
    "            else:\n",
    "                self.remainder_dim = input_dim % self.num_groups\n",
    "                self.rounded_input_dim = input_dim - self.remainder_dim\n",
    "            self.norm = nn.GroupNorm(self.num_groups, self.rounded_input_dim)\n",
    "            if self.remainder_dim > 0:\n",
    "                self.remainder_norm = nn.LayerNorm(self.remainder_dim)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == \"GroupNorm\":\n",
    "            if self.remainder_dim == 0:\n",
    "                self.norm(x)\n",
    "            else:\n",
    "                split_x1, split_x2 = torch.split(x, [self.rounded_input_dim, self.remainder_dim])\n",
    "                norm_x1 = self.norm(split_x1)\n",
    "                norm_x2 = self.remainder_norm(split_x2)\n",
    "                return torch.cat([norm_x1, norm_x2], -1)\n",
    "        else:\n",
    "            return self.norm(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, token_dim: int, dropout: float = 0.0, max_len: int = 5000, learnable: bool = False):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.learnable = learnable\n",
    "        if self.learnable:\n",
    "            self.pe = nn.Parameter(torch.normal(mean=0, std=0.001, size=(1, max_len, token_dim)))\n",
    "        else:\n",
    "            position = torch.arange(max_len).unsqueeze(1)\n",
    "            div_term = torch.exp(torch.arange(0, token_dim, 2) * (-math.log(10000.0) / token_dim))\n",
    "            pe = torch.zeros(1, max_len, token_dim)\n",
    "            pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "            pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "            self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MyTransformerEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_token_dim=64,\n",
    "                 output_token_dim=16,\n",
    "                 num_token=20,\n",
    "                 nhead=16,\n",
    "                 dim_feedforward=256,\n",
    "                 dropout=0.1,\n",
    "                 activation='gelu',\n",
    "                 nlayers=3,\n",
    "                 positional_encoding=True,\n",
    "                 proj_norm_mode=\"LayerNorm\",\n",
    "                 ):\n",
    "        super(MyTransformerEncoder, self).__init__()\n",
    "        self.input_token_dim = input_token_dim\n",
    "        self.output_token_dim = output_token_dim\n",
    "        self.num_token = num_token\n",
    "        self.positional_encoding = positional_encoding\n",
    "        if input_token_dim % 2 == 0:\n",
    "            self.corrected_input_token_dim = input_token_dim\n",
    "        else:\n",
    "            self.corrected_input_token_dim = input_token_dim + 1\n",
    "        self.transformer_pre_projection = nn.Sequential(\n",
    "            nn.Linear(self.input_token_dim, self.corrected_input_token_dim, bias=True),\n",
    "            MyNorm(self.corrected_input_token_dim, mode=proj_norm_mode),\n",
    "            MyActF(activation),\n",
    "        )\n",
    "        if positional_encoding:\n",
    "            self.pos_encoder = PositionalEncoding(token_dim=self.corrected_input_token_dim, dropout=0.0, max_len=num_token, learnable=False)\n",
    "        else:\n",
    "            self.pos_encoder = None\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.corrected_input_token_dim,\n",
    "                                                   nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation=activation,\n",
    "                                                   batch_first=True,\n",
    "                                                   norm_first=True,)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.transformer_final_projection = nn.Sequential(\n",
    "            nn.Linear(self.corrected_input_token_dim, self.output_token_dim, bias=True),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, num_token, input_token_dim]\n",
    "        output:\n",
    "            y: Tensor, shape [batch_size, num_token, output_token_dim]\n",
    "        \"\"\"\n",
    "        bs, t, d = x.size(0), x.size(1), x.size(2)\n",
    "        assert d == self.input_token_dim\n",
    "        \n",
    "        x_t = x.view(bs * t, d).contiguous()\n",
    "        proj_x = self.transformer_pre_projection(x_t)  # [batch_size, num_token, input_token_dim]\n",
    "        proj_x_t = proj_x.view(bs, t, self.corrected_input_token_dim).contiguous()\n",
    "        \n",
    "        # proj_x_t = x\n",
    "        \n",
    "        if self.positional_encoding:\n",
    "            endcoded_x = self.pos_encoder(proj_x_t)\n",
    "        else:\n",
    "            endcoded_x = proj_x_t\n",
    "        transformed_x = self.transformer_encoder(endcoded_x)\n",
    "        transformed_x_t = transformed_x.view(bs * t, self.corrected_input_token_dim).contiguous()\n",
    "        proj_transformed_x = self.transformer_final_projection(transformed_x_t).view(bs, t, self.output_token_dim).contiguous()\n",
    "        return proj_transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6a3802-81a7-4fff-8d4e-4557be38346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "\n",
    "# a simple average meter class for monitoring averages\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count if self.count != 0 else 0\n",
    "        \n",
    "# function to get memory usage\n",
    "def mem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 ** 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e51d4d-da49-46ee-95ad-7daa07075ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "refreshing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxchu/miniconda3/envs/tfcal_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# training variables\n",
    "num_epoch = 1000\n",
    "batch_size = 400\n",
    "test_batch_size = batch_size * 4\n",
    "num_of_sample_per_epoch = batch_size * 500\n",
    "num_of_test_sample = 10000\n",
    "lr = 1e-5\n",
    "lr_factor = 0.1\n",
    "lr_patience = 3\n",
    "lr_threshold=lr * 0.1\n",
    "warmup_epoch = 10\n",
    "warmup_factor = 2\n",
    "wd = 0.0001\n",
    "GPUs = [0]\n",
    "\n",
    "# datasets\n",
    "train_dataset = CustomDataset(num_of_sample_per_epoch)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataset = CustomDataset(num_of_test_sample, random_seed=1234567890)\n",
    "test_dataloader = data_utils.DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "# model\n",
    "model = MyTransformerEncoder(\n",
    "    input_token_dim=input_embed_dim,\n",
    "    output_token_dim=output_embed_dim,\n",
    "    num_token=input_dim,\n",
    "    nhead=6,\n",
    "    dim_feedforward=1024,\n",
    "    dropout=0.1,\n",
    "    activation='gelu',\n",
    "    nlayers=64,\n",
    "    positional_encoding=True,\n",
    "    proj_norm_mode=\"LayerNorm\", # LayerNorm BatchNorm\n",
    ")\n",
    "model = torch.nn.DataParallel(model, device_ids=GPUs).cuda()\n",
    "\n",
    "# optimizer\n",
    "train_parameters = model.parameters()\n",
    "optimizer = torch.optim.AdamW(train_parameters, lr=lr, weight_decay=wd)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=lr_factor,\n",
    "    patience=lr_patience,\n",
    "    threshold=lr_threshold,\n",
    "    threshold_mode='rel')\n",
    "\n",
    "# loss\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "# loss_function = nn.MSELoss(reduction=\"mean\")\n",
    "# class CustomLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomLoss, self).__init__()\n",
    "#         self.mseloss = nn.MSELoss(reduction='mean')\n",
    "\n",
    "#     def forward(self, output, target):\n",
    "#         batch_size = output.size(0)\n",
    "#         n_token = output.size(1)\n",
    "#         heatmaps_pred = output.reshape((batch_size, n_token, -1)).split(1, 1)\n",
    "#         heatmaps_gt = target.reshape((batch_size, n_token, -1)).split(1, 1)\n",
    "#         loss = 0\n",
    "\n",
    "#         for idx in range(n_token):\n",
    "#             heatmap_pred = heatmaps_pred[idx].squeeze()\n",
    "#             heatmap_gt = heatmaps_gt[idx].squeeze()\n",
    "#             loss += 0.5 * self.mseloss(heatmap_pred, heatmap_gt)\n",
    "\n",
    "#         return loss / n_token\n",
    "# loss_function = CustomLoss().cuda()\n",
    "\n",
    "# helper functions\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def set_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5e43a-8714-46bb-9a4b-81d74e30e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'checkpoint/checkpoint.pth'\n",
      "=> loaded checkpoint 'checkpoint/checkpoint.pth' (epoch 11)\n",
      "Epoch 11|lr:0.01024|Memory: 1.66 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fba5e232ef45f2a28201ebd4d522b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155999dd41eb48178345a2726e3f7e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['579+467+959              ', '107+957                  ']\n",
      "sample_raw_output ['2005                     ', '1064                     '] sample_raw_pred ['2495544400061145611144561', '1199922242000606666622256']\n",
      "sample_output [2005.0, 1064.0] sample_pred [2.495544400061146e+24, 1.1999222420006066e+24]\n",
      "sample_input ['837+511-930+793          ', '622+734+129-338          ']\n",
      "sample_raw_output ['1211                     ', '1147                     '] sample_raw_pred ['1145444000060001111104411', '1143544400000001111124411']\n",
      "sample_output [1211.0, 1147.0] sample_pred [1.145444000060001e+24, 1.1435444000000011e+24]\n",
      "sample_input ['926-116+585              ', '844*628-685              ']\n",
      "sample_raw_output ['1395                     ', '529347                   '] sample_raw_pred ['1145400000011111111124411', '4955559040000101111144111']\n",
      "sample_output [1395.0, 529347.0] sample_pred [1.1454000000111111e+24, 4.955559040000101e+24]\n",
      "sample_input ['550+307*148+617+665      ', '(208-268)-272            ']\n",
      "sample_raw_output ['47268                    ', '-332                     '] sample_raw_pred ['1499554554400002000144111', '-113444446000-------144--']\n",
      "sample_output [47268.0, -332.0] sample_pred [1.499554554400002e+24, 0.0]\n",
      "sample_input ['809-829                  ', '836-(904)+594            ']\n",
      "sample_raw_output ['-20                      ', '526                      '] sample_raw_pred ['-193540144----------141--', '-144900000000-1-----14---']\n",
      "sample_output [-20.0, 526.0] sample_pred [0.0, 0.0]\n",
      "sample_input ['800*686*994+14+221       ', '44+712-(((92)))-129      ']\n",
      "sample_raw_output ['545507435                ', '535                      '] sample_raw_pred ['4995599544000000161144111', '-19554644400--400-0-144--']\n",
      "sample_output [545507435.0, 535.0] sample_pred [4.995599544000001e+24, 0.0]\n",
      "sample_input ['261*729                  ', '(450)+370                ']\n",
      "sample_raw_output ['190269                   ', '820                      '] sample_raw_pred ['1995950220000111111124611', '1145000000011111111104011']\n",
      "sample_output [190269.0, 820.0] sample_pred [1.995950220000111e+24, 1.145000000011111e+24]\n",
      "[Epoch:11]|avg_loss:0.442968|lr:0.01024|avg_diff_ratio:1544108108889922207744.000|avg_loss_test:0.434077|avg_diff_ratio_test:1166149421137364254720.000|best_test_monitor:0.434|patient_count:0/3|Memory: 1.70 GB\n",
      "refreshing dataset...\n",
      "Epoch 12|lr:0.01024|Memory: 1.91 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b163a59984e48d3b207742b610a6572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85db7de94a284c1799e70b78ad9a91dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['379-942                  ', '322*540+295+35*15        ']\n",
      "sample_raw_output ['-563                     ', '174700                   '] sample_raw_pred ['-540440500----------41---', '1004404400000000011100111']\n",
      "sample_output [-563.0, 174700.0] sample_pred [0.0, 1.0044044000000001e+24]\n",
      "sample_input ['713+150*442              ', '872*(214)+6              ']\n",
      "sample_raw_output ['67013                    ', '186614                   '] sample_raw_pred ['1004440000001144111100111', '2004444400006100111100411']\n",
      "sample_output [67013.0, 186614.0] sample_pred [1.0044400000011441e+24, 2.0044444000061e+24]\n",
      "sample_input ['387+325-771-630-672      ', '91*720+187*(80)-829      ']\n",
      "sample_raw_output ['-1361                    ', '79651                    '] sample_raw_pred ['-100004000004-4404--10---', '1044444444000020400100111']\n",
      "sample_output [-1361.0, 79651.0] sample_pred [0.0, 1.0444444440000204e+24]\n",
      "sample_input ['37-932+969               ', '910+(402)*859            ']\n",
      "sample_raw_output ['74                       ', '346228                   '] sample_raw_pred ['1004404000411111111100011', '1004044000000104111100411']\n",
      "sample_output [74.0, 346228.0] sample_pred [1.0044040004111111e+24, 1.0040440000001041e+24]\n",
      "sample_input ['380+((776-(281)*869))+834', '772+572                  ']\n",
      "sample_raw_output ['-242199                  ', '1344                     '] sample_raw_pred ['-104004400000000000-10004', '1340444240000000000124001']\n",
      "sample_output [-242199.0, 1344.0] sample_pred [0.0, 1.34044424e+24]\n",
      "sample_input ['693*39                   ', '404*727                  ']\n",
      "sample_raw_output ['27027                    ', '293708                   '] sample_raw_pred ['3444401440000000111104011', '3049440440000011111104711']\n",
      "sample_output [27027.0, 293708.0] sample_pred [3.44440144e+24, 3.049440440000011e+24]\n",
      "sample_input ['((176)+395)+411+205      ', '3*717                    ']\n",
      "sample_raw_output ['1187                     ', '2151                     '] sample_raw_pred ['2444444400440004004100472', '1400044000000004111140112']\n",
      "sample_output [1187.0, 2151.0] sample_pred [2.444444400440004e+24, 1.400044000000004e+24]\n",
      "[Epoch:12]|avg_loss:0.438947|lr:0.01024|avg_diff_ratio:1992068215975536754688.000|avg_loss_test:0.435475|avg_diff_ratio_test:1445257334031371993088.000|best_test_monitor:0.434|patient_count:1/3|Memory: 1.91 GB\n",
      "refreshing dataset...\n",
      "Epoch 13|lr:0.01024|Memory: 1.91 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0075bbdc4e8b44c28a1fc62b97c85374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4640da1e6848cc9faf7f9c62fd84ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['117*863                  ', '980-793                  ']\n",
      "sample_raw_output ['100971                   ', '187                      '] sample_raw_pred ['1020222000000001111100000', '1100000000222-------0001-']\n",
      "sample_output [100971.0, 187.0] sample_pred [1.0202220000000011e+24, 0.0]\n",
      "sample_input ['925*713-13+176           ', '(168)-196                ']\n",
      "sample_raw_output ['659688                   ', '-28                      '] sample_raw_pred ['6022222222002023333420232', '-122200000021111111110111']\n",
      "sample_output [659688.0, -28.0] sample_pred [6.022222222002023e+24, -1.2220000002111112e+23]\n",
      "sample_input ['352-(510)+323            ', '925+990+630              ']\n",
      "sample_raw_output ['165                      ', '2545                     '] sample_raw_pred ['2000000000000111111100211', '2002220222221111111100011']\n",
      "sample_output [165.0, 2545.0] sample_pred [2.000000000000111e+24, 2.0022202222211111e+24]\n",
      "sample_input ['433-563                  ', '114-(169-730-821)-39     ']\n",
      "sample_raw_output ['-130                     ', '1457                     '] sample_raw_pred ['-100020162----------222--', '-1202020002000028000111--']\n",
      "sample_output [-130.0, 1457.0] sample_pred [0.0, 0.0]\n",
      "sample_input ['790*29                   ', '931+(286)*654            ']\n",
      "sample_raw_output ['22910                    ', '187975                   '] sample_raw_pred ['2002008626681111111100611', '1000200000000222222202222']\n",
      "sample_output [22910.0, 187975.0] sample_pred [2.002008626681111e+24, 1.0002000000002223e+24]\n",
      "sample_input ['300+578                  ', '134-184                  ']\n",
      "sample_raw_output ['878                      ', '-50                      '] sample_raw_pred ['8222000000644444444400044', '-12000010011221112--10011']\n",
      "sample_output [878.0, -50.0] sample_pred [8.222000000644444e+24, 0.0]\n",
      "sample_input ['873-829                  ', '((176)+395)+411+205      ']\n",
      "sample_raw_output ['44                       ', '1187                     '] sample_raw_pred ['-100000000----------202--', '1002202000020002202122221']\n",
      "sample_output [44.0, 1187.0] sample_pred [0.0, 1.0022020000200021e+24]\n",
      "[Epoch:13]|avg_loss:0.431259|lr:0.01024|avg_diff_ratio:1224608114625470267392.000|avg_loss_test:0.424117|avg_diff_ratio_test:1032860605090730344448.000|best_test_monitor:0.424|patient_count:0/3|Memory: 1.91 GB\n",
      "refreshing dataset...\n",
      "Epoch 14|lr:0.01024|Memory: 1.92 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3639ff2238394e969df881ac406dc39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2c06ae4c1444fea334d6d81e3103fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['94*47-270+624            ', '312+189-413*302          ']\n",
      "sample_raw_output ['4772                     ', '-124225                  '] sample_raw_pred ['4055500000000111111111111', '-110000005250000----111--']\n",
      "sample_output [4772.0, -124225.0] sample_pred [4.055500000000111e+24, 0.0]\n",
      "sample_input ['752-299-(530*(414))-314  ', '819-830*646              ']\n",
      "sample_raw_output ['-219281                  ', '-535361                  '] sample_raw_pred ['-11525505225500000001221-', '-5155255500---------12---']\n",
      "sample_output [-219281.0, -535361.0] sample_pred [0.0, 0.0]\n",
      "sample_input ['387+325-771-630-672      ', '635*185+10               ']\n",
      "sample_raw_output ['-1361                    ', '117485                   '] sample_raw_pred ['-122225155580050004-201--', '1115542004000000004000000']\n",
      "sample_output [-1361.0, 117485.0] sample_pred [0.0, 1.115542004e+24]\n",
      "sample_input ['693-505+27               ', '87*363*350               ']\n",
      "sample_raw_output ['215                      ', '11053350                 '] sample_raw_pred ['2105550000511111111152511', '1052200000111111111110111']\n",
      "sample_output [215.0, 11053350.0] sample_pred [2.105550000511111e+24, 1.0522000001111111e+24]\n",
      "sample_input ['179*646+773-630          ', '30-971*216*204-768       ']\n",
      "sample_raw_output ['115777                   ', '-42786882                '] sample_raw_pred ['1011124044000000088600000', '-10500500240000000--111--']\n",
      "sample_output [115777.0, -42786882.0] sample_pred [1.0111240440000001e+24, 0.0]\n",
      "sample_input ['404*(906)-447-752        ', '(251+886+426)-866*290    ']\n",
      "sample_raw_output ['364825                   ', '-249577                  '] sample_raw_pred ['3255555550000000011125111', '-1225000000000000010020--']\n",
      "sample_output [364825.0, -249577.0] sample_pred [3.25555555e+24, 0.0]\n",
      "sample_input ['17*672*240               ', '229*866-914              ']\n",
      "sample_raw_output ['2741760                  ', '197400                   '] sample_raw_pred ['2050000000111111111110111', '1855555044400000000055000']\n",
      "sample_output [2741760.0, 197400.0] sample_pred [2.050000000111111e+24, 1.8555550444e+24]\n",
      "[Epoch:14]|avg_loss:0.436231|lr:0.01024|avg_diff_ratio:1794356533159274741760.000|avg_loss_test:0.414972|avg_diff_ratio_test:1650487072738087272448.000|best_test_monitor:0.415|patient_count:0/3|Memory: 1.91 GB\n",
      "refreshing dataset...\n",
      "Epoch 15|lr:0.01024|Memory: 1.92 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0895077872b44a1d8ff76968ee93deb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ea2f287cf64b20bf5c6f1c9b8f9857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['429+(895-(787))-512      ', '743+997                  ']\n",
      "sample_raw_output ['25                       ', '1740                     '] sample_raw_pred ['-146400004000210011-141--', '1766066660244444444446444']\n",
      "sample_output [25.0, 1740.0] sample_pred [0.0, 1.7660666602444444e+24]\n",
      "sample_input ['910*352-432*594*494      ', '894+(255+550)-82+188     ']\n",
      "sample_raw_output ['-126444032               ', '1805                     '] sample_raw_pred ['-144666660000000000-111--', '1464460000000006061404141']\n",
      "sample_output [-126444032.0, 1805.0] sample_pred [0.0, 1.464460000000006e+24]\n",
      "sample_input ['131+807                  ', '219+758*387              ']\n",
      "sample_raw_output ['938                      ', '293565                   '] sample_raw_pred ['9066060060066666676646666', '3488886000011111111164011']\n",
      "sample_output [938.0, 293565.0] sample_pred [9.066060060066667e+24, 3.488886000011111e+24]\n",
      "sample_input ['163*429-92*210*794       ', '278-337                  ']\n",
      "sample_raw_output ['-15270153                ', '-59                      '] sample_raw_pred ['-10466666600000000---11--', '-1066004440---------111--']\n",
      "sample_output [-15270153.0, -59.0] sample_pred [0.0, 0.0]\n",
      "sample_input ['972*311*319+594-137      ', '267+582+235+988          ']\n",
      "sample_raw_output ['96431605                 ', '2072                     '] sample_raw_pred ['1164666466600000006420144', '2066466266600666611166661']\n",
      "sample_output [96431605.0, 2072.0] sample_pred [1.1646664666e+24, 2.0664662666006667e+24]\n",
      "sample_input ['217+686*913              ', '92+554*584*579           ']\n",
      "sample_raw_output ['626535                   ', '187327436                '] sample_raw_pred ['5666666000012421134414411', '2444464466000011111164661']\n",
      "sample_output [626535.0, 187327436.0] sample_pred [5.666666000012421e+24, 2.444464466000011e+24]\n",
      "sample_input ['156-(653*591)+385        ', '945+925-346*336*587      ']\n",
      "sample_raw_output ['-385382                  ', '-68240402                '] sample_raw_pred ['-44848444440-020-----11--', '-106666666600000006-111--']\n",
      "sample_output [-385382.0, -68240402.0] sample_pred [0.0, 0.0]\n",
      "[Epoch:15]|avg_loss:0.436584|lr:0.01024|avg_diff_ratio:1473770326959696379904.000|avg_loss_test:0.411376|avg_diff_ratio_test:1301874825319893958656.000|best_test_monitor:0.411|patient_count:0/3|Memory: 1.91 GB\n",
      "refreshing dataset...\n",
      "Epoch 16|lr:0.01024|Memory: 1.92 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fd1bac2324481ca3389de01e1f3326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb3eacc77354ba1b2b041dcfd402fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['924+18*664               ', '191-718+(484-571)*950    ']\n",
      "sample_raw_output ['12876                    ', '-83177                   '] sample_raw_pred ['1555555666666666000665666', '-2555555550060005000655--']\n",
      "sample_output [12876.0, -83177.0] sample_pred [1.555555666666666e+24, 0.0]\n",
      "sample_input ['711*932                  ', '(978*208)-197-569*159    ']\n",
      "sample_raw_output ['662652                   ', '112756                   '] sample_raw_pred ['6555566655222244444455244', '-1555556666000000052622--']\n",
      "sample_output [662652.0, 112756.0] sample_pred [6.555566655222245e+24, 0.0]\n",
      "sample_input ['(530+611)+715*564+412    ', '(60-881*306)-32*809      ']\n",
      "sample_raw_output ['404813                   ', '-295414                  '] sample_raw_pred ['6555555565660606060665522', '-255555555660006060455544']\n",
      "sample_output [404813.0, -295414.0] sample_pred [6.555555565660606e+24, -2.5555555566000606e+23]\n",
      "sample_input ['0+(520+719-566)-990      ', '614*(4*(603)+638)+879    ']\n",
      "sample_raw_output ['-317                     ', '1873579                  '] sample_raw_pred ['-2566600000000-0000--155-', '5555555565666666266565211']\n",
      "sample_output [-317.0, 1873579.0] sample_pred [0.0, 5.555555565666667e+24]\n",
      "sample_input ['23+56                    ', '882*(743)+874-351*987    ']\n",
      "sample_raw_output ['79                       ', '309763                   '] sample_raw_pred ['5555556555665555555565556', '1055555505666666560655555']\n",
      "sample_output [79.0, 309763.0] sample_pred [5.555556555665555e+24, 1.0555555056666666e+24]\n",
      "sample_input ['698*856-892*488          ', '415+436-700              ']\n",
      "sample_raw_output ['162192                   ', '151                      '] sample_raw_pred ['-15555565660000----226---', '2156000000025-22222-550--']\n",
      "sample_output [162192.0, 151.0] sample_pred [0.0, 0.0]\n",
      "sample_input ['422+870*494*698          ', '514-592+669+143          ']\n",
      "sample_raw_output ['299986862                ', '734                      '] sample_raw_pred ['4555555555660002222215112', '9055666600000062555525555']\n",
      "sample_output [299986862.0, 734.0] sample_pred [4.555555555660002e+24, 9.055666600000063e+24]\n",
      "[Epoch:16]|avg_loss:0.427778|lr:0.01024|avg_diff_ratio:2138133321952555696128.000|avg_loss_test:0.412740|avg_diff_ratio_test:1653875609245218504704.000|best_test_monitor:0.411|patient_count:1/3|Memory: 1.91 GB\n",
      "refreshing dataset...\n",
      "Epoch 17|lr:0.01024|Memory: 1.92 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e78bfb4c1ac4603be21dad737763e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fca56542f3434ea0e5e0188fbdf555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# monitoring variables\n",
    "begin_epoch = 0\n",
    "avg_loss = AverageMeter()\n",
    "avg_loss_test = AverageMeter()\n",
    "avg_diff_ratio = AverageMeter()\n",
    "avg_diff_ratio_test = AverageMeter()\n",
    "best_test_monitor = float(np.inf)\n",
    "best_epoch = 0\n",
    "patient_count = 0\n",
    "\n",
    "# checkpoint paths\n",
    "checkpoint_dir = \"checkpoint\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
    "checkpoint_best_path = os.path.join(checkpoint_dir, \"checkpoint_best.pth\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"=> loading checkpoint '{}'\".format(checkpoint_path))\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    begin_epoch = checkpoint['epoch']\n",
    "    best_epoch = checkpoint['best_epoch']\n",
    "    best_test_monitor = checkpoint['best_test_monitor']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(checkpoint_path, begin_epoch))\n",
    "\n",
    "current_lr = lr\n",
    "# set_lr(optimizer, 1e-4)\n",
    "skip_first_epoch = False\n",
    "for epoch in range(begin_epoch, num_epoch):\n",
    "    current_lr = get_lr(optimizer)\n",
    "    print(f\"Epoch {epoch}|lr:{current_lr}|Memory: {mem():.2f} GB...\")\n",
    "    \n",
    "    if not skip_first_epoch or epoch > 0:\n",
    "        # training\n",
    "        model.train()\n",
    "        for train_data in tqdm(train_dataloader):\n",
    "            model_pred = model(train_data[0])\n",
    "            train_loss = loss_function(model_pred.view(-1, output_embed_dim), train_data[1].view(-1, output_embed_dim).to(model_pred.device))\n",
    "\n",
    "            # loss and accuracy monitor\n",
    "            avg_loss.update(train_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(train_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-3))\n",
    "            avg_diff_ratio.update(diff_ratio)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_data in tqdm(test_dataloader):\n",
    "            model_pred = model(test_data[0])\n",
    "            test_loss = loss_function(model_pred.view(-1, output_embed_dim), test_data[1].view(-1, output_embed_dim).to(model_pred.device))\n",
    "            \n",
    "            # loss and accuracy monitor\n",
    "            avg_loss_test.update(test_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(test_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-3))\n",
    "            avg_diff_ratio_test.update(diff_ratio)\n",
    "    \n",
    "            # display some example\n",
    "            test_input_data_numpy = test_data[0].numpy()\n",
    "            current_batch_size = test_input_data_numpy.shape[0]\n",
    "            sample_idx = np.random.choice(current_batch_size, 2)\n",
    "            sample_input = decode_nn_data(test_input_data_numpy[sample_idx], is_input=True)\n",
    "            sample_raw_output = decode_nn_data(test_data[1].numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            sample_output = decode_nn_data(test_data[1].numpy()[sample_idx], is_input=False, apply_float=True)\n",
    "            sample_raw_pred = decode_nn_data(model_pred.cpu().detach().numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            sample_pred = decode_nn_data(model_pred.cpu().detach().numpy()[sample_idx], is_input=False, apply_float=True)\n",
    "            print(\"sample_input\", sample_input)\n",
    "            print(\"sample_raw_output\", sample_raw_output, \"sample_raw_pred\", sample_raw_pred)\n",
    "            print(\"sample_output\", sample_output, \"sample_pred\", sample_pred)\n",
    "\n",
    "    # update best_test_monitor\n",
    "    # test_monitor = avg_diff_ratio_test.val\n",
    "    test_monitor = avg_loss_test.val\n",
    "    if test_monitor != float(\"inf\") and test_monitor != float('nan') and test_monitor < best_test_monitor:\n",
    "        best_test_monitor = test_monitor\n",
    "        best_epoch = epoch + 1\n",
    "        patient_count = 0\n",
    "        \n",
    "        # save best checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_test_monitor': best_test_monitor,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, checkpoint_best_path)\n",
    "    else:\n",
    "        patient_count += 1\n",
    "\n",
    "    print(f\"[Epoch:{epoch}]|avg_loss:{avg_loss.val:.6f}|lr:{current_lr}|avg_diff_ratio:{avg_diff_ratio.val:.3f}|avg_loss_test:{avg_loss_test.val:.6f}|avg_diff_ratio_test:{avg_diff_ratio_test.val:.3f}|\"\n",
    "          f\"best_test_monitor:{best_test_monitor:.3f}|patient_count:{patient_count}/{lr_patience}|Memory: {mem():.2f} GB\")\n",
    "    \n",
    "    # update learning rate if needed\n",
    "    if epoch < warmup_epoch:\n",
    "        print(f\"warming up! increase learning rate from {current_lr:.8f} to {current_lr * warmup_factor:.8f}\")\n",
    "        set_lr(optimizer, current_lr * warmup_factor)\n",
    "        patient_count = 0\n",
    "    else:\n",
    "        if patient_count >= lr_patience and current_lr > lr_threshold:\n",
    "            print(f\"reach patient threshold! reducing learning rate from {current_lr:.8f} to {current_lr * lr_factor:.8f}\")\n",
    "            set_lr(optimizer, current_lr * lr_factor)\n",
    "            patient_count = 0\n",
    "    \n",
    "    # save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_test_monitor': best_test_monitor,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # reset variables\n",
    "    avg_loss.reset()\n",
    "    avg_loss_test.reset()\n",
    "    avg_diff_ratio.reset()\n",
    "    avg_diff_ratio_test.reset()\n",
    "    train_dataloader.dataset.refresh_data()\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c80cd1-329d-43ea-9a65-c4086e04f386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3132f025-57b8-4c26-8361-46967e82833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA:0 _CudaDeviceProperties(name='NVIDIA GeForce GTX 1070', major=6, minor=1, total_memory=8105MB, multi_processor_count=15) [(8004.625, 8105.0625)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# logging jupiterlab notebook \n",
    "import logging\n",
    "nblog = open(\"nb.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# GPU infos\n",
    "num_GPUs = torch.cuda.device_count()\n",
    "for i in range(num_GPUs):\n",
    "    info = torch.cuda.get_device_properties(i)\n",
    "    mem_info = torch.cuda.mem_get_info(i)\n",
    "    print(f\"CUDA:{i} {info} [{mem_info[0]/ 1024 ** 2, mem_info[1]/ 1024 ** 2}]\")\n",
    "\n",
    "# variables\n",
    "# operators = ['-', '+', '*', '/']\n",
    "operators = ['+', '-', '*']\n",
    "brackets = ['(', ')']\n",
    "input_chars = [\" \"] + [str(d) for d in range(10)] + [\".\"] + operators + brackets\n",
    "output_chars = [\" \"] + [str(d) for d in range(10)] + [\"-\"]\n",
    "max_number = 999\n",
    "max_digit = 5\n",
    "max_bracket = 3\n",
    "input_dim = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555245d4-25fb-4168-97fa-9685dcf126ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating simple arithematic equations and answers\n",
    "def generate_equation():\n",
    "    # number of numbers will be in the equation\n",
    "    num_digits = random.randint(2, max_digit)  # Choose a random number of digits for each operand\n",
    "\n",
    "    # Generate a list of elements in equation\n",
    "    equations = []\n",
    "    for i in range(num_digits):\n",
    "        equations.append(str(random.randint(0, max_number)))\n",
    "        if i < num_digits - 1:\n",
    "            equations.append(random.choice(operators))\n",
    "\n",
    "    # Add brackets randomly\n",
    "    num_brackets = random.randint(0, max_bracket)\n",
    "    for _ in range(num_brackets):\n",
    "        pos1 = random.randint(0, len(equations) - 1)\n",
    "        while equations[pos1] in operators + brackets:\n",
    "            pos1 += 1\n",
    "        new_equations = equations[:pos1] + ['('] + equations[pos1:]\n",
    "        \n",
    "        pos2 = random.randint(pos1 + 2, len(new_equations))\n",
    "        while 2 < pos2 < len(new_equations) and new_equations[pos2 - 1] in operators + brackets:\n",
    "            pos2 += 1\n",
    "        if pos2 == len(new_equations):\n",
    "            continue\n",
    "        new_equations = new_equations[:pos2] + [')'] + new_equations[pos2:]\n",
    "        equations = new_equations\n",
    "\n",
    "    # concatenate them into a single string\n",
    "    final_equation = \"\".join(equations)\n",
    "    return final_equation\n",
    "\n",
    "# evaluate the equation and get the result\n",
    "def evaluate_equation(equation):\n",
    "    try:\n",
    "        # result = f\"{{:.6f}}\".format(eval(equation)).zfill(input_dim)\n",
    "        result = str(eval(equation))\n",
    "        return result\n",
    "    except ZeroDivisionError:\n",
    "        return \" \" * input_dim\n",
    "\n",
    "# function to generate a string equation with answer\n",
    "def generate_eq():\n",
    "    # Generate and evaluate a random equation\n",
    "    equation = generate_equation()\n",
    "    result = evaluate_equation(equation)\n",
    "    return equation, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d91eb00-3b10-440d-8671-ba2020ae13fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(836*581+7)-435', '485288')\n",
      "('867-250', '617')\n",
      "('749+575+186*186', '35920')\n",
      "('385+382+(521)*80', '42447')\n",
      "('818-839', '-21')\n"
     ]
    }
   ],
   "source": [
    "# generate some examples\n",
    "for _ in range(5):\n",
    "    print(generate_eq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3025da8-7ac2-4a0b-b121-39304e6c48f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input string length: 25\n",
      "Max result string length: 15\n",
      "Min result string: -517989972133\n",
      "Max result string: 444670589082720\n",
      "Number of invalid input string: 0/100000 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# run the generation function many times to get the maxium length of the equation and maximum range of the answer\n",
    "num_trail = 100000\n",
    "max_len_eq = 0\n",
    "max_len_result = 0\n",
    "max_result = float(-np.inf)\n",
    "min_result = float(np.inf)\n",
    "max_result_str = None\n",
    "min_result_str = None\n",
    "invalid_count = 0\n",
    "for _ in range(num_trail):\n",
    "    equation, result = generate_eq()\n",
    "    if \"!\" not in result:\n",
    "        fresult = float(result)\n",
    "        if fresult > max_result:\n",
    "            max_result = fresult\n",
    "            max_result_str = result\n",
    "        if fresult < min_result:\n",
    "            min_result = fresult\n",
    "            min_result_str = result\n",
    "    else:\n",
    "        invalid_count += 1\n",
    "    len_eq, len_result = len(equation), len(result)\n",
    "    max_len_eq = len_eq if len_eq > max_len_eq else max_len_eq\n",
    "    max_len_result = len_result if len_result > max_len_result else max_len_result\n",
    "\n",
    "print(f\"Max input string length: {max_len_eq}\")\n",
    "print(f\"Max result string length: {max_len_result}\")\n",
    "print(f\"Min result string: {min_result_str}\")\n",
    "print(f\"Max result string: {max_result_str}\")\n",
    "print(f\"Number of invalid input string: {invalid_count}/{num_trail} = {invalid_count/num_trail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e134e9-1d01-4b0d-9b9e-66b1a14f3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.', '+', '-', '*', '(', ')'] input_embed_dim 17\n",
      "output_chars [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'] output_embed_dim 12\n",
      "==========[input_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      ". [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "+ [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "* [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "( [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      ") [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[output_embed_map]============\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "- [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "==========[input_embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 .\n",
      "12 +\n",
      "13 -\n",
      "14 *\n",
      "15 (\n",
      "16 )\n",
      "==========[output_embed_inverse_map]============\n",
      "0  \n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 -\n"
     ]
    }
   ],
   "source": [
    "# the embedding dimensions and mappings\n",
    "input_embed_dim = len(input_chars)\n",
    "output_embed_dim = len(output_chars)\n",
    "print(\"input_chars\", input_chars, \"input_embed_dim\", input_embed_dim)\n",
    "print(\"output_chars\", output_chars, \"output_embed_dim\", output_embed_dim)\n",
    "input_embed_map = {e: np.eye(input_embed_dim)[i] for i, e in enumerate(input_chars)}\n",
    "output_embed_map = {e: np.eye(output_embed_dim)[i] for i, e in enumerate(output_chars)}\n",
    "input_embed_inverse_map = {i: k for i, k in enumerate(input_embed_map.keys())}\n",
    "output_embed_inverse_map = {i: k for i, k in enumerate(output_embed_map.keys())}\n",
    "\n",
    "print(\"==========[input_embed_map]============\")\n",
    "for k in input_embed_map.keys():\n",
    "    print(k, input_embed_map[k])\n",
    "\n",
    "print(\"==========[output_embed_map]============\")\n",
    "for k in output_embed_map.keys():\n",
    "    print(k, output_embed_map[k])\n",
    "\n",
    "print(\"==========[input_embed_inverse_map]============\")\n",
    "for k in input_embed_inverse_map.keys():\n",
    "    print(k, input_embed_inverse_map[k])\n",
    "    \n",
    "print(\"==========[output_embed_inverse_map]============\")\n",
    "for k in output_embed_inverse_map.keys():\n",
    "    print(k, output_embed_inverse_map[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4562a51-d95a-4493-a419-e9514d465d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input data: [('622*309-501*934-668', '-276404'), ('44*608+241+138', '27131')]\n",
      "raw input size: input=(2, 25, 17), output=(2, 25, 12)\n",
      "time_spent: 0.0004749298095703125s\n"
     ]
    }
   ],
   "source": [
    "# function to generate neural netowrk (nn) data for the Transformer\n",
    "def generate_nn_data(num_sample, outout_raw_data_pair=False):\n",
    "    data_pair = [generate_eq() for _ in range(num_sample)]\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for i in range(num_sample):\n",
    "        i_str = data_pair[i][0]\n",
    "        o_str = data_pair[i][1]\n",
    "        \n",
    "        i_vec = np.zeros((input_dim, input_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(reversed(i_str)):\n",
    "            i_vec[input_dim - i - 1] = input_embed_map[char]\n",
    "        input_data.append(i_vec)\n",
    "\n",
    "        j_vec = np.zeros((input_dim, output_embed_dim), dtype=np.float32)\n",
    "        for i, char in enumerate(reversed(o_str)):\n",
    "            j_vec[input_dim - i - 1] = output_embed_map[char]\n",
    "        output_data.append(j_vec)\n",
    "\n",
    "    input_data = np.array(input_data, dtype=np.float32)\n",
    "    output_data = np.array(output_data, dtype=np.float32)\n",
    "    if outout_raw_data_pair:\n",
    "        return input_data, output_data, data_pair\n",
    "    else:\n",
    "        return input_data, output_data\n",
    "\n",
    "time_start = time.time()\n",
    "input_data, output_data, data_pair = generate_nn_data(2, outout_raw_data_pair=True)\n",
    "time_spent = time.time() - time_start\n",
    "print(f\"raw input data: {data_pair}\")\n",
    "print(f\"raw input size: input={input_data.shape}, output={output_data.shape}\")\n",
    "print(f\"time_spent: {time_spent}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5819827-45b0-4f19-8d81-3687734080e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : ['      622*309-501*934-668', '           44*608+241+138']\n",
      "output: ['                  -276404', '                    27131']\n"
     ]
    }
   ],
   "source": [
    "# function to decode the nn data back to string\n",
    "def decode_nn_data(output_nn_data, is_input, apply_float=False):\n",
    "    decoded_output = []\n",
    "    c_batchsize =  output_nn_data.shape[0]\n",
    "    c_slen =  output_nn_data.shape[1]\n",
    "    if is_input:\n",
    "        embed_inverse_map = input_embed_inverse_map\n",
    "    else:\n",
    "        embed_inverse_map = output_embed_inverse_map\n",
    "    for b in range(c_batchsize):\n",
    "        e_output = [embed_inverse_map[np.argmax(output_nn_data[b][s])] for s in range(c_slen)]\n",
    "        joint_e_output = \"\".join(e_output)\n",
    "        if apply_float:\n",
    "            try:\n",
    "                decoded_output.append(float(joint_e_output))\n",
    "            except:\n",
    "                decoded_output.append(0.0)\n",
    "        else:\n",
    "            decoded_output.append(joint_e_output)\n",
    "    return decoded_output\n",
    "print(f\"input : {decode_nn_data(input_data, is_input=True, apply_float=False)}\")\n",
    "print(f\"output: {decode_nn_data(output_data, is_input=False, apply_float=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b81ff04-5ed9-4d14-8ca5-0efe4ca75ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "input: ['       776-41-988*497-940', '            288+(773)+633'], output: ['                  -491241', '                     1694']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n",
      "input: ['                  920*338', '   453*266+824*((937))+95'], output: ['                   310960', '                   892681']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n",
      "input: ['              939*227+822', '                   82-896'], output: ['                   213975', '                     -814']\n",
      "input size: torch.Size([2, 25, 17]), output size: torch.Size([2, 25, 12])\n"
     ]
    }
   ],
   "source": [
    "# our custom pytorch dataset class\n",
    "class CustomDataset(data_utils.Dataset):\n",
    "    def __init__(self, num_sample, random_seed=0):\n",
    "        random.seed(0)\n",
    "        self.num_sample = num_sample\n",
    "        self.refresh_data()\n",
    "\n",
    "    def refresh_data(self):\n",
    "        print(\"refreshing dataset...\")\n",
    "        self.input_data, self.output_data = generate_nn_data(self.num_sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.output_data[idx]\n",
    "\n",
    "train_dataset = CustomDataset(6)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=2)\n",
    "for i in train_dataloader:\n",
    "    print(f\"input: {decode_nn_data(i[0].numpy(), is_input=True)}, output: {decode_nn_data(i[1].numpy(), is_input=False)}\")\n",
    "    print(f\"input size: {i[0].shape}, output size: {i[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62568ee-b33a-4c72-96cb-98be9069c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes and functions for our basic Transformer model\n",
    "class SwiGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        return F.silu(gate) * x\n",
    "\n",
    "class MyActF(nn.Module):\n",
    "    def __init__(self, mode=\"silu\"):\n",
    "        super().__init__()\n",
    "        if mode == \"leaky_relu\":\n",
    "            self.act_f = nn.LeakyReLU(negative_slope=0.01)\n",
    "        elif mode == \"relu\":\n",
    "            self.act_f = nn.ReLU()\n",
    "        elif mode == \"gelu\":\n",
    "            self.act_f = nn.GELU()\n",
    "        elif mode in [\"silu\", \"swish\"]:\n",
    "            self.act_f = nn.SiLU()\n",
    "        elif mode == \"hardswish\":\n",
    "            self.act_f = nn.Hardswish()\n",
    "        elif mode == \"SwiGLU\":\n",
    "            self.act_f = SwiGLU()\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act_f(x)\n",
    "\n",
    "\n",
    "class BatchRenorm(torch.jit.ScriptModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        eps: float = 1e-3,\n",
    "        momentum: float = 0.01,\n",
    "        affine: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"running_std\", torch.ones(num_features, dtype=torch.float))\n",
    "        self.register_buffer(\"num_batches_tracked\", torch.tensor(0, dtype=torch.long))\n",
    "        self.weight = torch.nn.Parameter(torch.ones(num_features, dtype=torch.float))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(num_features, dtype=torch.float))\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        self.step = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        raise NotImplementedError()  # pragma: no cover\n",
    "\n",
    "    @property\n",
    "    def rmax(self) -> torch.Tensor:\n",
    "        return (2 / 35000 * self.num_batches_tracked + 25 / 35).clamp_(1.0, 3.0)\n",
    "\n",
    "    @property\n",
    "    def dmax(self) -> torch.Tensor:\n",
    "        return (5 / 20000 * self.num_batches_tracked - 25 / 20).clamp_(0.0, 5.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self._check_input_dim(x)\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        if self.training:\n",
    "            dims = [i for i in range(x.dim() - 1)]\n",
    "            batch_mean = x.mean(dims)\n",
    "            batch_std = x.std(dims, unbiased=False) + self.eps\n",
    "            r = (batch_std.detach() / self.running_std.view_as(batch_std)).clamp_(1 / self.rmax, self.rmax)\n",
    "            d = ((batch_mean.detach() - self.running_mean.view_as(batch_mean)) / self.running_std.view_as(batch_std)).clamp_(-self.dmax, self.dmax)\n",
    "            x = (x - batch_mean) / batch_std * r + d\n",
    "            self.running_mean += self.momentum * (batch_mean.detach() - self.running_mean)\n",
    "            self.running_std += self.momentum * (batch_std.detach() - self.running_std)\n",
    "            self.num_batches_tracked += 1\n",
    "        else:\n",
    "            x = (x - self.running_mean) / self.running_std\n",
    "        if self.affine:\n",
    "            x = self.weight * x + self.bias\n",
    "        if x.dim() > 2:\n",
    "            x = x.transpose(1, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BatchRenorm1d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() not in [2, 3]:\n",
    "            raise ValueError(\"expected 2D or 3D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm2d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(\"expected 4D input (got {x.dim()}D input)\")\n",
    "\n",
    "\n",
    "class BatchRenorm3d(BatchRenorm):\n",
    "    def _check_input_dim(self, x: torch.Tensor) -> None:\n",
    "        if x.dim() != 5:\n",
    "            raise ValueError(\"expected 5D input (got {x.dim()}D input)\")\n",
    "\n",
    "class MyNorm(nn.Module):\n",
    "    def __init__(self, input_dim, mode=\"BatchNorm\"):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        if mode == \"LayerNorm\":\n",
    "            self.norm = nn.LayerNorm(input_dim)\n",
    "        elif mode == \"BatchNorm\":\n",
    "            self.norm = nn.BatchNorm1d(input_dim)\n",
    "        elif mode == \"BatchRenorm\":\n",
    "            self.norm = BatchRenorm1d(input_dim)\n",
    "        elif mode == \"GroupNorm\":\n",
    "            self.num_groups = 8\n",
    "            self.remainder_dim = None\n",
    "            self.rounded_input_dim = None\n",
    "            if self.num_groups > input_dim:\n",
    "                self.num_groups = 1\n",
    "                self.remainder_dim = 0\n",
    "                self.rounded_input_dim = input_dim\n",
    "            else:\n",
    "                self.remainder_dim = input_dim % self.num_groups\n",
    "                self.rounded_input_dim = input_dim - self.remainder_dim\n",
    "            self.norm = nn.GroupNorm(self.num_groups, self.rounded_input_dim)\n",
    "            if self.remainder_dim > 0:\n",
    "                self.remainder_norm = nn.LayerNorm(self.remainder_dim)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == \"GroupNorm\":\n",
    "            if self.remainder_dim == 0:\n",
    "                self.norm(x)\n",
    "            else:\n",
    "                split_x1, split_x2 = torch.split(x, [self.rounded_input_dim, self.remainder_dim])\n",
    "                norm_x1 = self.norm(split_x1)\n",
    "                norm_x2 = self.remainder_norm(split_x2)\n",
    "                return torch.cat([norm_x1, norm_x2], -1)\n",
    "        else:\n",
    "            return self.norm(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, token_dim: int, dropout: float = 0.0, max_len: int = 5000, learnable: bool = False):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.learnable = learnable\n",
    "        if self.learnable:\n",
    "            self.pe = nn.Parameter(torch.normal(mean=0, std=0.001, size=(1, max_len, token_dim)))\n",
    "        else:\n",
    "            position = torch.arange(max_len).unsqueeze(1)\n",
    "            div_term = torch.exp(torch.arange(0, token_dim, 2) * (-math.log(10000.0) / token_dim))\n",
    "            pe = torch.zeros(1, max_len, token_dim)\n",
    "            pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "            pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "            self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MyTransformerEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_token_dim=64,\n",
    "                 output_token_dim=16,\n",
    "                 num_token=20,\n",
    "                 nhead=16,\n",
    "                 dim_feedforward=256,\n",
    "                 dropout=0.1,\n",
    "                 activation='gelu',\n",
    "                 nlayers=3,\n",
    "                 positional_encoding=True,\n",
    "                 proj_norm_mode=\"LayerNorm\",\n",
    "                 ):\n",
    "        super(MyTransformerEncoder, self).__init__()\n",
    "        self.input_token_dim = input_token_dim\n",
    "        self.output_token_dim = output_token_dim\n",
    "        self.num_token = num_token\n",
    "        self.positional_encoding = positional_encoding\n",
    "        if input_token_dim % 2 == 0:\n",
    "            self.corrected_input_token_dim = input_token_dim\n",
    "        else:\n",
    "            self.corrected_input_token_dim = input_token_dim + 1\n",
    "        self.transformer_pre_projection = nn.Sequential(\n",
    "            nn.Linear(self.input_token_dim, self.corrected_input_token_dim, bias=False),\n",
    "            MyNorm(self.corrected_input_token_dim, mode=proj_norm_mode),\n",
    "            MyActF(activation),\n",
    "        )\n",
    "        if positional_encoding:\n",
    "            self.pos_encoder = PositionalEncoding(token_dim=self.corrected_input_token_dim, dropout=0.0, max_len=num_token, learnable=False)\n",
    "        else:\n",
    "            self.pos_encoder = None\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.corrected_input_token_dim,\n",
    "                                                   nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation=activation,\n",
    "                                                   batch_first=True,\n",
    "                                                   norm_first=True,)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.transformer_final_projection = nn.Sequential(\n",
    "            nn.Linear(self.corrected_input_token_dim, self.output_token_dim, bias=True),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, num_token, input_token_dim]\n",
    "        output:\n",
    "            y: Tensor, shape [batch_size, num_token, output_token_dim]\n",
    "        \"\"\"\n",
    "        bs, t, d = x.size(0), x.size(1), x.size(2)\n",
    "        assert d == self.input_token_dim\n",
    "        \n",
    "        x_t = x.view(bs * t, d).contiguous()\n",
    "        proj_x = self.transformer_pre_projection(x_t)  # [batch_size, num_token, input_token_dim]\n",
    "        proj_x_t = proj_x.view(bs, t, self.corrected_input_token_dim).contiguous()\n",
    "        \n",
    "        # proj_x_t = x\n",
    "        \n",
    "        if self.positional_encoding:\n",
    "            endcoded_x = self.pos_encoder(proj_x_t)\n",
    "        else:\n",
    "            endcoded_x = proj_x_t\n",
    "        transformed_x = self.transformer_encoder(endcoded_x)\n",
    "        transformed_x_t = transformed_x.view(bs * t, self.corrected_input_token_dim).contiguous()\n",
    "        proj_transformed_x = self.transformer_final_projection(transformed_x_t).view(bs, t, self.output_token_dim).contiguous()\n",
    "        return proj_transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6a3802-81a7-4fff-8d4e-4557be38346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "\n",
    "# a simple average meter class for monitoring averages\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count if self.count != 0 else 0\n",
    "        \n",
    "# function to get memory usage\n",
    "def mem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 ** 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e51d4d-da49-46ee-95ad-7daa07075ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing dataset...\n",
      "refreshing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxchu/miniconda3/envs/tfcal_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# training variables\n",
    "num_epoch = 1000\n",
    "batch_size = 1000\n",
    "test_batch_size = batch_size * 4\n",
    "num_of_sample_per_epoch = batch_size * 500\n",
    "num_of_test_sample = 10000\n",
    "lr = 1e-3\n",
    "wd = 0.001\n",
    "lr_factor = 0.1\n",
    "lr_patience = 5\n",
    "lr_threshold=lr * 0.1\n",
    "warmup_epoch = 5\n",
    "warmup_factor = 10.0**(1.0/warmup_epoch)\n",
    "GPUs = list(range(num_GPUs))\n",
    "\n",
    "# datasets\n",
    "train_dataset = CustomDataset(num_of_sample_per_epoch)\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataset = CustomDataset(num_of_test_sample, random_seed=1234567890)\n",
    "test_dataloader = data_utils.DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "# model\n",
    "model = MyTransformerEncoder(\n",
    "    input_token_dim=input_embed_dim,\n",
    "    output_token_dim=output_embed_dim,\n",
    "    num_token=input_dim,\n",
    "    nhead=6,\n",
    "    dim_feedforward=1024,\n",
    "    dropout=0.1,\n",
    "    activation='gelu',\n",
    "    nlayers=32,\n",
    "    positional_encoding=True,\n",
    "    proj_norm_mode=\"LayerNorm\", # LayerNorm BatchNorm\n",
    ")\n",
    "model = torch.nn.DataParallel(model, device_ids=GPUs).cuda()\n",
    "\n",
    "# optimizer\n",
    "train_parameters = model.parameters()\n",
    "optimizer = torch.optim.AdamW(train_parameters, lr=lr, weight_decay=wd)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer,\n",
    "#     mode='min',\n",
    "#     factor=lr_factor,\n",
    "#     patience=lr_patience,\n",
    "#     threshold=lr_threshold,\n",
    "#     threshold_mode='rel')\n",
    "\n",
    "# loss\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"mean\").cuda()\n",
    "# loss_function = nn.MSELoss(reduction=\"mean\")\n",
    "# class CustomLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomLoss, self).__init__()\n",
    "#         self.mseloss = nn.MSELoss(reduction='mean')\n",
    "\n",
    "#     def forward(self, output, target):\n",
    "#         batch_size = output.size(0)\n",
    "#         n_token = output.size(1)\n",
    "#         heatmaps_pred = output.reshape((batch_size, n_token, -1)).split(1, 1)\n",
    "#         heatmaps_gt = target.reshape((batch_size, n_token, -1)).split(1, 1)\n",
    "#         loss = 0\n",
    "\n",
    "#         for idx in range(n_token):\n",
    "#             heatmap_pred = heatmaps_pred[idx].squeeze()\n",
    "#             heatmap_gt = heatmaps_gt[idx].squeeze()\n",
    "#             loss += 0.5 * self.mseloss(heatmap_pred, heatmap_gt)\n",
    "\n",
    "#         return loss / n_token\n",
    "# loss_function = CustomLoss().cuda()\n",
    "\n",
    "# helper functions\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def set_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5e43a-8714-46bb-9a4b-81d74e30e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'checkpoint/checkpoint.pth'\n",
      "=> loaded checkpoint 'checkpoint/checkpoint.pth' (epoch 42)\n",
      "Epoch 42|lr:0.010000000000000005|Memory: 3.30 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2727db738454f9a843cbe1963b1590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6fed0ab7184511a54983e7b466a306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['       219*871-418+22*761', '   (153+167-(382*639))+16']\n",
      "sample_raw_output ['                   207073', '                  -243762'] sample_raw_pred ['                   377888', '                  -258888']\n",
      "sample_output [207073.0, -243762.0] sample_pred [377888.0, -258888.0]\n",
      "sample_input ['       882*558-845+948+90', '                   118-59']\n",
      "sample_raw_output ['                   492349', '                       59'] sample_raw_pred ['                   588888', '                       18']\n",
      "sample_output [492349.0, 59.0] sample_pred [588888.0, 18.0]\n",
      "sample_input ['                (346)-332', '                  878-211']\n",
      "sample_raw_output ['                       14', '                      667'] sample_raw_pred ['                       18', '                      788']\n",
      "sample_output [14.0, 667.0] sample_pred [18.0, 788.0]\n",
      "[Epoch:42]|avg_loss:0.418425|lr:0.010000000000000005|avg_diff_ratio:0.545|avg_loss_test:0.420385|avg_diff_ratio_test:602.180|best_test_monitor:0.417|best_epoch:42|patient_count:1/5|Memory: 3.36 GB\n",
      "refreshing dataset...\n",
      "Epoch 43|lr:0.010000000000000005|Memory: 3.55 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7c4549eb8d48ce9be4085b7643ea1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c285965a8f13455ab5d6ec4d183c97ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['              798-227-679', '       732-29+804-443*932']\n",
      "sample_raw_output ['                     -108', '                  -411369'] sample_raw_pred ['                     -242', '                  -422226']\n",
      "sample_output [-108.0, -411369.0] sample_pred [-242.0, -422226.0]\n",
      "sample_input ['    600*820+(712+668)-364', '       30*101+879*214-752']\n",
      "sample_raw_output ['                   493016', '                   190384'] sample_raw_pred ['                   726222', '                   202626']\n",
      "sample_output [493016.0, 190384.0] sample_pred [726222.0, 202626.0]\n",
      "sample_input ['       96+584*365*758+619', '                  399+983']\n",
      "sample_raw_output ['                161575995', '                     1382'] sample_raw_pred ['                162262225', '                     1322']\n",
      "sample_output [161575995.0, 1382.0] sample_pred [162262225.0, 1322.0]\n",
      "[Epoch:43]|avg_loss:0.438493|lr:0.010000000000000005|avg_diff_ratio:113332216.000|avg_loss_test:0.417614|avg_diff_ratio_test:683.658|best_test_monitor:0.417|best_epoch:42|patient_count:2/5|Memory: 3.37 GB\n",
      "refreshing dataset...\n",
      "Epoch 44|lr:0.010000000000000005|Memory: 3.56 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f8d1e1b4374284b16b1586147cefc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fb9e3be717425192f8b4285d16abd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['      795*717+(3-560)+380', '               108+614*93']\n",
      "sample_raw_output ['                   569838', '                    57210'] sample_raw_pred ['                   400000', '                    50000']\n",
      "sample_output [569838.0, 57210.0] sample_pred [400000.0, 50000.0]\n",
      "sample_input ['                  807*142', '      550+307*148+617+665']\n",
      "sample_raw_output ['                   114594', '                    47268'] sample_raw_pred ['                   100006', '                    40000']\n",
      "sample_output [114594.0, 47268.0] sample_pred [100006.0, 40000.0]\n",
      "sample_input ['              694-789+967', '           690+457+48+120']\n",
      "sample_raw_output ['                      872', '                     1315'] sample_raw_pred ['                     1900', '                     1200']\n",
      "sample_output [872.0, 1315.0] sample_pred [1900.0, 1200.0]\n",
      "[Epoch:44]|avg_loss:0.429186|lr:0.010000000000000005|avg_diff_ratio:0.908|avg_loss_test:0.409048|avg_diff_ratio_test:555.455|best_test_monitor:0.409|best_epoch:45|patient_count:0/5|Memory: 3.56 GB\n",
      "refreshing dataset...\n",
      "Epoch 45|lr:0.010000000000000005|Memory: 3.56 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96eaa68aa7804721b35c068db983c585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8712667f6943e5b8e5c5e112755319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['          755*959*918*304', '    780+570*(787)-967-586']\n",
      "sample_raw_output ['             202060686240', '                   447817'] sample_raw_pred ['             177000700000', '                   411110']\n",
      "sample_output [202060686240.0, 447817.0] sample_pred [177000700000.0, 411110.0]\n",
      "sample_input ['       14+560*124-968-641', '                   961*73']\n",
      "sample_raw_output ['                    67845', '                    70153'] sample_raw_pred ['                    61007', '                    71711']\n",
      "sample_output [67845.0, 70153.0] sample_pred [61007.0, 71711.0]\n",
      "sample_input ['              520*191-469', '     661*707-941*(55)+141']\n",
      "sample_raw_output ['                    98851', '                   415713'] sample_raw_pred ['                    01111', '                   441110']\n",
      "sample_output [98851.0, 415713.0] sample_pred [1111.0, 441110.0]\n",
      "[Epoch:45]|avg_loss:0.420979|lr:0.010000000000000005|avg_diff_ratio:1.384|avg_loss_test:0.401817|avg_diff_ratio_test:55.413|best_test_monitor:0.402|best_epoch:46|patient_count:0/5|Memory: 3.56 GB\n",
      "refreshing dataset...\n",
      "Epoch 46|lr:0.010000000000000005|Memory: 3.56 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf443aff90f345b396a470a4a37c3e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0ec9ac24cc4ea4acb158ed7a9730b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['                  821-516', '      654*522+926+721-984']\n",
      "sample_raw_output ['                      305', '                   342051'] sample_raw_pred ['                      225', '                   325555']\n",
      "sample_output [305.0, 342051.0] sample_pred [225.0, 325555.0]\n",
      "sample_input ['          463+70-(48)*788', '    940-(538*552-430)+283']\n",
      "sample_raw_output ['                   -37291', '                  -295323'] sample_raw_pred ['                   -35555', '                  -315552']\n",
      "sample_output [-37291.0, -295323.0] sample_pred [-35555.0, -315552.0]\n",
      "sample_input ['    444+(701-889-885)-993', '                  165*800']\n",
      "sample_raw_output ['                    -1622', '                   132000'] sample_raw_pred ['                     -555', '                   145550']\n",
      "sample_output [-1622.0, 132000.0] sample_pred [-555.0, 145550.0]\n",
      "[Epoch:46]|avg_loss:0.415076|lr:0.010000000000000005|avg_diff_ratio:125.488|avg_loss_test:0.400851|avg_diff_ratio_test:282.915|best_test_monitor:0.401|best_epoch:47|patient_count:0/5|Memory: 3.56 GB\n",
      "refreshing dataset...\n",
      "Epoch 47|lr:0.010000000000000005|Memory: 3.57 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e863c8878f1f4ecf8fb00d46dfa7c1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215d3e2e292c44048e3ec2710f930f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['       74*637+401*883-756', '          825+86-(174)-42']\n",
      "sample_raw_output ['                   400465', '                      695'] sample_raw_pred ['                   444443', '                     1043']\n",
      "sample_output [400465.0, 695.0] sample_pred [444443.0, 1043.0]\n",
      "sample_input ['        983-284+(825)*895', '    (814*760)+313-703*379']\n",
      "sample_raw_output ['                   739074', '                   352516'] sample_raw_pred ['                   644444', '                   544443']\n",
      "sample_output [739074.0, 352516.0] sample_pred [644444.0, 544443.0]\n",
      "sample_input ['  (625*757-680-(435))-100', '       (173-397)+(74)+507']\n",
      "sample_raw_output ['                   471910', '                      357'] sample_raw_pred ['                   344445', '                      344']\n",
      "sample_output [471910.0, 357.0] sample_pred [344445.0, 344.0]\n",
      "[Epoch:47]|avg_loss:0.416205|lr:0.010000000000000005|avg_diff_ratio:0.833|avg_loss_test:0.393262|avg_diff_ratio_test:177.441|best_test_monitor:0.393|best_epoch:48|patient_count:0/5|Memory: 3.56 GB\n",
      "refreshing dataset...\n",
      "Epoch 48|lr:0.010000000000000005|Memory: 3.57 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2a154a1ce840b6b05b7f6bf3d30578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3bc6b8e7bd4108aa437eb899eda8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['              325-605+247', '    608*(589*751*516)*534']\n",
      "sample_raw_output ['                      -33', '           74105385308928'] sample_raw_pred ['                      139', '           77777979780000']\n",
      "sample_output [-33.0, 74105385308928.0] sample_pred [139.0, 77777979780000.0]\n",
      "sample_input ['                   127-43', '       30*101+879*214-752']\n",
      "sample_raw_output ['                       84', '                   190384'] sample_raw_pred ['                       72', '                   187779']\n",
      "sample_output [84.0, 190384.0] sample_pred [72.0, 187779.0]\n",
      "sample_input ['                  482+170', '                  336-750']\n",
      "sample_raw_output ['                      652', '                     -414'] sample_raw_pred ['                      672', '                     -496']\n",
      "sample_output [652.0, -414.0] sample_pred [672.0, -496.0]\n",
      "[Epoch:48]|avg_loss:0.406195|lr:0.010000000000000005|avg_diff_ratio:2.479|avg_loss_test:0.384931|avg_diff_ratio_test:90.475|best_test_monitor:0.385|best_epoch:49|patient_count:0/5|Memory: 3.56 GB\n",
      "refreshing dataset...\n",
      "Epoch 49|lr:0.010000000000000005|Memory: 3.57 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c44f84cbf904603860b15635c68cb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068a0a5dc0184afe885fe5cb6d63b832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input ['                  193*232', '            (981-229)-869']\n",
      "sample_raw_output ['                    44776', '                     -117'] sample_raw_pred ['                    47774', '                     -237']\n",
      "sample_output [44776.0, -117.0] sample_pred [47774.0, -237.0]\n",
      "sample_input ['         887*(879)-403-40', '            356-698-6*964']\n",
      "sample_raw_output ['                   779230', '                    -6126'] sample_raw_pred ['                   777676', '                    -6766']\n",
      "sample_output [779230.0, -6126.0] sample_pred [777676.0, -6766.0]\n",
      "sample_input ['                  786+766', '                (884)-826']\n",
      "sample_raw_output ['                     1552', '                       58'] sample_raw_pred ['                     1460', '                       30']\n",
      "sample_output [1552.0, 58.0] sample_pred [1460.0, 30.0]\n",
      "[Epoch:49]|avg_loss:0.403530|lr:0.010000000000000005|avg_diff_ratio:521.263|avg_loss_test:0.381122|avg_diff_ratio_test:93.642|best_test_monitor:0.381|best_epoch:50|patient_count:0/5|Memory: 3.57 GB\n",
      "refreshing dataset...\n",
      "Epoch 50|lr:0.010000000000000005|Memory: 3.57 GB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd74a7d4407425facaea4395f927446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# monitoring variables\n",
    "begin_epoch = 0\n",
    "avg_loss = AverageMeter()\n",
    "avg_loss_test = AverageMeter()\n",
    "avg_diff_ratio = AverageMeter()\n",
    "avg_diff_ratio_test = AverageMeter()\n",
    "best_test_monitor = float(np.inf)\n",
    "best_epoch = 0\n",
    "patient_count = 0\n",
    "\n",
    "# checkpoint paths\n",
    "checkpoint_dir = \"checkpoint\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
    "checkpoint_best_path = os.path.join(checkpoint_dir, \"checkpoint_best.pth\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"=> loading checkpoint '{}'\".format(checkpoint_path))\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    begin_epoch = checkpoint['epoch']\n",
    "    best_epoch = checkpoint['best_epoch']\n",
    "    best_test_monitor = checkpoint['best_test_monitor']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(checkpoint_path, begin_epoch))\n",
    "\n",
    "current_lr = lr\n",
    "# set_lr(optimizer, 1e-4)\n",
    "skip_first_epoch = True\n",
    "for epoch in range(begin_epoch, num_epoch):\n",
    "    current_lr = get_lr(optimizer)\n",
    "    print(f\"Epoch {epoch}|lr:{current_lr}|Memory: {mem():.2f} GB...\")\n",
    "    \n",
    "    if not skip_first_epoch or epoch > 0:\n",
    "        # training\n",
    "        model.train()\n",
    "        for train_data in tqdm(train_dataloader):\n",
    "            model_pred = model(train_data[0])\n",
    "            target_indices = torch.argmax(train_data[1].view(-1, output_embed_dim).cuda(non_blocking=True), dim=1)\n",
    "            train_loss = loss_function(model_pred.view(-1, output_embed_dim), target_indices)\n",
    "\n",
    "            # loss and accuracy monitor\n",
    "            avg_loss.update(train_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(train_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-3))\n",
    "            avg_diff_ratio.update(diff_ratio)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_data in tqdm(test_dataloader):\n",
    "            model_pred = model(test_data[0])\n",
    "            target_indices = torch.argmax(test_data[1].view(-1, output_embed_dim).cuda(non_blocking=True), dim=1)\n",
    "            test_loss = loss_function(model_pred.view(-1, output_embed_dim), target_indices)\n",
    "            \n",
    "            # loss and accuracy monitor\n",
    "            avg_loss_test.update(test_loss.cpu().detach().numpy().item())\n",
    "            gt_result = np.array(decode_nn_data(test_data[1].numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            pred_result = np.array(decode_nn_data(model_pred.cpu().detach().numpy(), is_input=False, apply_float=True), dtype=np.float32)\n",
    "            diff_ratio = np.mean(np.absolute(gt_result - pred_result) / (np.absolute(gt_result) + 1e-3))\n",
    "            avg_diff_ratio_test.update(diff_ratio)\n",
    "    \n",
    "            # display some example\n",
    "            test_input_data_numpy = test_data[0].numpy()\n",
    "            current_batch_size = test_input_data_numpy.shape[0]\n",
    "            sample_idx = np.random.choice(current_batch_size, 2)\n",
    "            sample_input = decode_nn_data(test_input_data_numpy[sample_idx], is_input=True)\n",
    "            sample_raw_output = decode_nn_data(test_data[1].numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            sample_output = decode_nn_data(test_data[1].numpy()[sample_idx], is_input=False, apply_float=True)\n",
    "            sample_raw_pred = decode_nn_data(model_pred.cpu().detach().numpy()[sample_idx], is_input=False, apply_float=False)\n",
    "            sample_pred = decode_nn_data(model_pred.cpu().detach().numpy()[sample_idx], is_input=False, apply_float=True)\n",
    "            print(\"sample_input\", sample_input)\n",
    "            print(\"sample_raw_output\", sample_raw_output, \"sample_raw_pred\", sample_raw_pred)\n",
    "            print(\"sample_output\", sample_output, \"sample_pred\", sample_pred)\n",
    "\n",
    "    # update best_test_monitor\n",
    "    # test_monitor = avg_diff_ratio_test.val\n",
    "    test_monitor = avg_loss_test.val\n",
    "    if test_monitor != float(\"inf\") and test_monitor != float('nan') and test_monitor < best_test_monitor:\n",
    "        best_test_monitor = test_monitor\n",
    "        best_epoch = epoch + 1\n",
    "        patient_count = 0\n",
    "        \n",
    "        # save best checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_test_monitor': best_test_monitor,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, checkpoint_best_path)\n",
    "    else:\n",
    "        patient_count += 1\n",
    "\n",
    "    print(f\"[Epoch:{epoch}]|avg_loss:{avg_loss.val:.6f}|lr:{current_lr}|avg_diff_ratio:{avg_diff_ratio.val:.3f}|avg_loss_test:{avg_loss_test.val:.6f}|avg_diff_ratio_test:{avg_diff_ratio_test.val:.3f}|\"\n",
    "          f\"best_test_monitor:{best_test_monitor:.3f}|best_epoch:{best_epoch}|patient_count:{patient_count}/{lr_patience}|Memory: {mem():.2f} GB\")\n",
    "    \n",
    "    # update learning rate if needed\n",
    "    if epoch < warmup_epoch:\n",
    "        print(f\"warming up! increase learning rate from {current_lr:.8f} to {current_lr * warmup_factor:.8f}\")\n",
    "        set_lr(optimizer, current_lr * warmup_factor)\n",
    "        patient_count = 0\n",
    "    else:\n",
    "        if patient_count >= lr_patience and current_lr > lr_threshold:\n",
    "            print(f\"reach patient threshold! reducing learning rate from {current_lr:.8f} to {current_lr * lr_factor:.8f}\")\n",
    "            set_lr(optimizer, current_lr * lr_factor)\n",
    "            patient_count = 0\n",
    "    \n",
    "    # save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_test_monitor': best_test_monitor,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # reset variables\n",
    "    avg_loss.reset()\n",
    "    avg_loss_test.reset()\n",
    "    avg_diff_ratio.reset()\n",
    "    avg_diff_ratio_test.reset()\n",
    "    train_dataloader.dataset.refresh_data()\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c80cd1-329d-43ea-9a65-c4086e04f386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
